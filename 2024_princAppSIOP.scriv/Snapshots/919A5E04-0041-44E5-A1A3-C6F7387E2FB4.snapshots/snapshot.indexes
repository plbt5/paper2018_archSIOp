<?xml version="1.0" encoding="UTF-8"?>
<SnapshotIndexes Version="1.0" BinderUUID="919A5E04-0041-44E5-A1A3-C6F7387E2FB4">
    <Snapshot Date="2023-11-16 17:51:31 +0100">
        <Title>Naar versie 2</Title>
        <Text>[@Greefhorst2011] provides for a Principles Catalogue in their appendix which presents almost sixty design principles. Principle A.20 of them reads *Data that are exchanged adhere to a canonical data model*, and one of its rationals states that *A Canonical Data Model standardises the definitions of data that are exchanged (...)*. Indeed, principle A.20 reflects the current practises to achieve interoperability. Although it conflicts with our \cref{loosely-coupled-semantics}, it is not necessarily wrong, since following it results in achieving interoperability as justified by the many if not all interoperable systems that exist today. However, its application is founded on local solutions, leading to large (domain size) semantic monoliths and their issues. Besides, local solutions are difficult to turn into generic components and, hence, impedes infrastructural solutions towards sIOP. 

Several works exist that address the architectural foundations related to information analyses and interoperability, both in academic literature [@Karagiannis2006;@Raghupathi2008] and in industrial practices [@ObjectManagementGroupOMG2013]. Few literature exists on on the combination of foundations for architectural concerns and those for formal semantics, and when they do they make use of ontological foundations to specify the semantics of the capabilities and resources of the architectural language as opposed to domain semantics [@Naudet2010;@Azevedo2015;@Carvalho2016]. 

The authors of [@Pagano2013a] present an abstract account of interoperability issues, research challenges and fundamental factors that apply in interoperability. In terms of these findings, our work can be considered on-topic, relevant, and in alignment with their research agenda. It distinguishes from theirs by addressing sIOP solutions to part of their broader and more abstract view on interoperability. 

The automatic tabular document exchange (DocEx) framework proposed by \cite{Yang2017} divides semantic interoperability into two stages: *interpretation*, described as automatic unambiguous information understanding, and *employment*, understood as the capability to automatically operate on the information according to the interpreted semantics. The interpretation phase is dependent on a global vocabulary that “provides uniquely coded and unambiguous concepts across different domains”. Essentially, this is a clear example of the *semantic standard fallacy* described by \cite{Janowicz:2013ui}: “The successful standardisation of protocols made us believe that we should also standardise meaning on the Web. This is a fundamental misconception”, particularly since it defies semantic heterogeneity and different but equally legitimate perspectives on the same thing. At the same time, separating an interpretation stage from an employment stage supports our position taken on the distinction between comprehension and telicity.


1. Pahl, C. (2007). Semantic model-driven architecting of service-based software systems. Information and Software Technology, 49(8), 838–850. https://doi.org/10.1016/J.INFSOF.2006.09.007 —&gt; Compare how they apply onto’s for DM
1. Overlap and differences with TOGAF/Archimate
1. Maybe discuss as agreement-based approach to sIOP: J.A. Mykkänen, M.P. Tuomainen, An evaluation and selection framework for interoperability standards, Information and Software Technology, Volume 50, Issue 3, 2008,Pages 176-197, ISSN 0950-5849, https://doi.org/10.1016/j.infsof.2006.12.001. (https://www.sciencedirect.com/science/article/pii/S0950584906001960)</Text>
    </Snapshot>
</SnapshotIndexes>