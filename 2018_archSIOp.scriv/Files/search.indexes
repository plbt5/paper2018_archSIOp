<?xml version="1.0" encoding="UTF-8"?>
<SearchIndexes Version="1.0">
    <Documents>
        <Document ID="39">
            <Title>Heavyweight vs lightweight extension</Title>
            <Text>The UML built-in extension mechanisms allow one to modify the
language elements to suite certain modeling needs. Extensions to the
language can be performed in two different ways: (i) by specializing the
UML metamodel (layer 2) to add new semantics to UML modeling
elements; or (ii) by changing the so-called MOF model (layer 3) to add new
elements to the UML metamodel. The former mechanism is named
lightweight extension and the latter heavyweight extension. A coherent set of such
extensions, defined accordingly to a specific purpose or domain, constitutes
a UML profile (OMG, 2003b).

Guizzardi2005</Text>
        </Document>
        <Document ID="61">
            <Title>Modeling</Title>
        </Document>
        <Document ID="54">
            <Title>View-based architectures</Title>
            <Text>Collaborating software components shall be able to establish equivalent abstractions of the state of affairs in their shared domain of application. Along the same lines and addressing local semantics, concerns exist about their maintainability and their ability to evolve, independently from collaborating peers and without exerting impact on peers to the greatest extent possible. No view-based architectural approaches provide support for these concerns, justifying an additional view(point) that we call the *Semantic View(point)*.  We use Kruchten’s 4+1 view model [@Kruchten1995], which underlies the IEEE standard 1471 [@IEEE2000;Maier2001], as reference architecture.  
&gt; I would here refer to ISO 42010 (IEEE 1471) rather than Kruchten, as it is not limited to 4 views. Meaning you will be able to define an additional view according to the standard to cover the semantics concerns.</Text>
        </Document>
        <Document ID="47">
            <Title>Semantics in software</Title>
            <Text>Data, be it numerical values, text strings, identifiers or even pictures and images, are representations of particular state of affairs in reality, expressed by tokens. Data are, thus, signifiers. Hence, the relationship between data (particularly their tokens) and their signified, e.g., a state of affairs in reality, is very real but tacit only. Still, to process data correctly, the application needs to know what the tokens stands for in reality, what is their scope, and what constraints it should apply. The tacit relation between the data tokens and the state of affairs in reality can be considered prior knowledge that is possessed by the application developers, only. And only when that prior knowledge has been applied correctly, it will result in a piece of software code that can process the data correctly, i.e., in accordance to what the data stands for. We, therefore, take the stance that for software systems, semantics should be understood as the very real but tacit relationship that exists between the (tokens representing) the data and the software code that processes that data in a very specific manner. Semantics is like the two sides of a sheet of paper: At the one side it shows the tokens that refer to something in reality, and at the other side it shows that particular piece of the software code that processes that data in accordance to what is considered valid about that particular reality. For instance, [INSERT AN EXAMPLE]. In conclusion, both the software code and the data, despite being separate entities that can stand on their own, are inseparable when establishing semantics.  There is one more aspect about semantics that we would like to highlight. According to [@Grice:1991BT;@Schulz2007], two sub-types of meaning exist. Firstly, *semantic meaning*, denotes semantics as how the tokens are meant to be interpreted, explained by Grice [@Grice:1991BT] as *"what is said"*: a heart rate reading of `128BPM` refers to a particular state of affairs where a person has been measured the frequency of his/her heart pulse of about 128 beats per minute, rhythmically generated by the sinoatrial node. We consider *semantic meaning* equivalent to our notion on semantics above. Secondly, Grice considers another sub-type that he explains as the *pragmatic meaning*, meaning based on rules governing the use of the semantic meaning. We like to consider this second sub-type as the meaning that emerges from the tokens in the specific context of use, i.e., the meaning that emerges beyond what is said when, e.g., drawing conclusions about the state of affairs. The heart rate reading of `128BPM`, although carried by the very same bits, can carry distinct pragmatic meaning in different domains: as an indication of health in the care domain, and as an indication of performance potential in domains of sports. It is not even necessary to change to another domain, because, when we elaborate on the indication of health, the same bits will refer to very different health conditions in the context of elderly than in the context of new-borns.   
DEFINITION: Semantics in software : The semantic meaning that emerges on processing the data, before the software commences with the pragmatic meaning.  
Note that according to our definition, semantics does not imply validity, i.e., being in accordance with the actual state of affairs.</Text>
        </Document>
        <Document ID="55">
            <Title>Basic design pattern to sIOP</Title>
            <Text>
&gt; The following picture provides for the grand picture on sIOP that serves as guidance to my research. Still, I think it is very illuminating as the essential framework for achieving sIOP.  
![enter image description here](https://i.imgur.com/Ql6yh0T.png)</Text>
        </Document>
        <Document ID="48">
            <Title>sIOP concerns and principles</Title>
            <Text>&gt; The following sections on concerns are very incomplete. They might not even present concerns yet. Some items may evolve into principles, others are just constraints to the solution, or open thoughts... &gt; Our first architectural principle is that sIOP should be designed to embrace semantic heterogeneity, to deal with semantics in another way than suggesting yet another semantic convention.</Text>
        </Document>
        <Document ID="62">
            <Title>Recovered Files (25 Sep 2018, 19:13)</Title>
        </Document>
        <Document ID="63">
            <Title>3.rtf</Title>
        </Document>
        <Document ID="56">
            <Title>Orphan text</Title>
            <Text>
With the absence of strong AI, only the application that generated the data possesses the know-how to "decode" the data, i.e., to what part of reality the data refer to. Actually, that know-how can be found in the precise way with which the software is designed to work with the particular data. For instance, a statement such as `read Patient.tempInC from Sensor_1`  "encodes" the know-how that the value produced by a sensor (i) refers to the body temperature (ii) of a patient (iii) in degrees Centigrade. As long as `Patient.tempInC` stays within the realm that is aware of that particular know-how, one can safely assume the same know-how will be applied consistently, e.g., in the statement `Patient.hasFever = (Patient.tempInC &gt; 38.0)` the know-how is applied consistently in the comparison with another value that refers to a critical body temperature in degrees Centigrade, the result of which is subsequently "encoded" as new know-how, here a referral to a particular state of the patient.

----

Access-and-play sIOP demands a notion on semantics, often denoted in layman’s terms as the “understanding of the data”. Despite the used terms *smart* or *intelligent*, e.g., smart watches, or intelligent autonomous systems, computers are inherently stupid. The notion of understanding is completely alien to them. In fact, it is the IT engineer who performs the understanding of data upfront, and implements the proper response to such understanding in program code. Nevertheless, we do. For instance, when we are asked to explain how we address the grounding problem in the design of our software agent, we can’t; when we are asked to point at the semantics parts in the code of our software agent, we can't. The same question however about, e.g., its scalability, will render a lecture with adequate references to the underlying architecture. We thus remain at a loss of how to engineer semantics into software agents. However, without a clear understanding on semantics and its contribution to the software agent, we are lacking the bridgehead within the software agent that is fundamental to the semantic interoperability bridge. Hence, the first architectural concern to consider is the nature of semantics in software, and we will address that in the next section. 





----

Although technologies such as the Semantic Web and ontologies are available, and despite the principles and practises of the model driven architecture paradigm, no architectural guidance to semantic interoperability exists, neither in terms of architectural principles nor as design practises.

Given the exponential growth in semantic heterogeneity that follows from distributed use of distributed supplied services over distributed resources, information systems are in a desperate need for a managed semantics, which, similar to the principle to store data only once in order to prevent data conflicts, controls the semantic heterogeneity from a central location in your architecture. Information systems are in a desperate need for an automated sIOP capability to break through this ceiling.



</Text>
        </Document>
        <Document ID="49">
            <Title>Semantic concerns</Title>
            <Text>The following concerns relate to an explicit role of semantic in software 
1. No universal semantics can exist. Different stakeholders will maintain different world views, each of them equally valid. Therefore, consider semantic heterogeneity a feature as opposed to a bug and thus design for semantic heterogeneity; 2. Each software component is about a particular application domain. As already indicated in the previous point, each software component will maintain a unique view on its application domain. We need to make that unique view explicit as opposed to leave it as implicit characteristic of the software component. As Quine notes: “We look to [...] ontology not in order to know *what there is*, but in order to know what a given remark or doctrine, ours or someone else’s, *says* there is” [@Quine:1953er]. Thus, prepare for sIOP by specifying your particular world view explicitly, upfront, as Conceptual Model (CM), i.e., local ontology. 1. Volume – the size of the ontology and the amount of instances, 2. Velocity – the speed at which data is generated, 3. Variety – data from multiple domains, 4. Variability – the change of characteristics of the data, which also causes a need to change the ontology  5. Evolution of knowledge and semantics</Text>
        </Document>
        <Document ID="64">
            <Title>4.rtf</Title>
        </Document>
        <Document ID="57">
            <Title>References</Title>
            <Text>1. Linington, P. F. (1995). RM-ODP: The Architecture. In Open Distributed Processing: Experience with Distributed Environments (pp. 15–33). Boston, MA: Springer US. https://doi.org/10.1007/978-0-387-34882-7_2 2. Kruchten, P. (1995). Architectural blueprints – the ”4+ 1” view model of software architecture. IEEE Software, 12(6), 42–50. https://doi.org/10.1145/216591.216611 3. Maier, M. W., Emery, D., &amp; Hilliard, R. (2001). Software architecture: Introducing IEEE standard 1471. Computer, 34(4), 107–109. https://doi.org/10.1109/2.917550 4. Zachman, J. A. (1987). A Framework for Information Systems Architecture. IBM Systmes Journal, 26(3), 454–470. https://doi.org/10.1147/sj.263.0276 5. (IAOA). (2013). The International Association for Ontology and its Applications (IAOA) - Activities. Retrieved December 3, 2017, from http://iaoa.org/activities/activities.html 6. (W3C). (2015). Semantic Web - W3C. Retrieved December 3, 2017, from https://www.w3.org/standards/semanticweb/ 7. Grice, H. P. (1989). Logic and Conversation. In Studies in the Way of Words (pp. 22–40). Cambridge, MA, USA: Harvard University Press. 8. Quine, W. V. O. (1961). From logical point of view. British Dental Journal, 195(5), 229. Retrieved from http://www.ncbi.nlm.nih.gov/pubmed/12973303 9. Schulz, K. (2007). Minimal Models in Semantics and Pragmatics. Universiteit van Amsterdam. Retrieved from http://hdl.handle.net/11245/1.272471 10. Saussure, F. (1983). Course in general linguistics. 11. Tolkien, J. R. R., &amp; Tolkien, C. (2002). The History of Middle-earth. HarperCollins Publishers. 12. Bass, L., Clements, P., &amp; Kazman, R. (2013). Software architecture in practice (3rd ed.). Addison-Wesley. 13. Zeist, R. H. J. van, &amp; Hendriks, P. R. H. (1996). Specifying software quality with the extended ISO model. Software Quality Journal, 5(4), 273–284. https://doi.org/10.1007/BF00209185 14. Guarino, N., Carrara, M., &amp; Giaretta, P. (1994). An Ontology of Meta-Level Categories. In Principles of Knowledge Representation and Reasoning: Proceedings of the Fourth International Conference (KR94) (pp. 270–280). https://doi.org/10.1.1.106.753 15. Euzenat, J., &amp; Shvaiko, P. (2013). Ontology Matching (2nd ed.). Springer. https://doi.org/10.1007/978-3-642-38721-0 16. Xiuquan Li, &amp; Tao Zhang. (2017). An exploration on artificial intelligence application: From security, privacy and ethic perspective. In J. Zhu, E.-B. Lin, &amp; T. Li (Eds.), 2017 IEEE 2nd International Conference on Cloud Computing and Big Data Analysis (ICCCBDA) (pp. 416–420). Xihua, China: IEEE. https://doi.org/10.1109/ICCCBDA.2017.7951949 17. Silva, P. de A., Ribeiro, C. M. F. A., &amp; Schiel, U. (2007). Formalizing ontology reconciliation techniques as a basis for meaningful mediation in service-related tasks. In Proceedings of the ACM first Ph.D. workshop in CIKM on - PIKM ’07 (pp. 147–154). Lisbon, Portugal: ACM Press. https://doi.org/10.1145/1316874.1316898 18. Hameed, A., Preece, A., &amp; Sleeman, D. (2004). Ontology Reconciliation. In S. Staab &amp; R. Stuber (Eds.), Handbook on Ontologies (pp. 231–250). Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-24750-0_12 19. Balachandar, K., Thirumagal, E., Aishwarya, D., &amp; Rajkumar, R. (2013). Ontology Mapping Techniques and Approaches. International Journal of Computer Applications, 65(24), 13–20. Retrieved from http://research.ijcaonline.org/volume65/number24/pxc3886514.pdf 20. Taye, M. M., &amp; Alalwan, N. (2010). Ontology Alignment Technique for Improving Semantic Integration. In M. Popescu (Ed.), SEMAPRO 2010 : The Fourth International Conference on Advances in Semantic Processing (pp. 13–18). Florence, Italy. Retrieved from http://www.thinkmind.org/index.php?view=article&amp;articleid=semapro_2010_1_30_50049 21. Scheider, S. (2012). Grounding geographic information in perceptual operations. IOS Press.  22. Steels, L. (2012). The symbol grounding problem has been solved, so what’s next. In M. de Vega, A. Glenberg, &amp; A. Graesser (Eds.), Symbols and Embodiment: Debates on Meaning and Cognition (pp. 223–244). Oxford, UK: Oxford University Press. https://doi.org/10.1093/acprof:oso/9780199217274.003.0012 23. Cregan, A. M. (2007). Symbol grounding for the semantic web. In W. Franconi, E and Kifer, M and May (Ed.), SEMANTIC WEB: RESEARCH AND APPLICATIONS, PROCEEDINGS (Vol. 4519, pp. 429–442). HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY: SPRINGER-VERLAG BERLIN.     
</Text>
        </Document>
        <Document ID="65">
            <Title>4_synopsis.txt</Title>
        </Document>
        <Document ID="58">
            <Title>Project Notes</Title>
        </Document>
        <Document ID="59">
            <Title>General</Title>
        </Document>
        <Document ID="3">
            <Title>MMD cheat sheet</Title>
            <Text>Source: [pandoc’s markdown](http://johnmacfarlane.net/pandoc/README.html#pandocs-markdown)

# Chapter levels, this is level 1 # {#identifier .class .class key=value key=value}

I can refer to [the very first chapter](#foo) or using the [autogenerated chapter id](#chapter-level-2).

The {attributes} should be positioned OUTSIDE the hash-enclosed chapter title.

## Chapter level 2 {#foo -}

The {-} attribute indicates an unnumbered header.

# A level-one header with a [link](/url) and *emphasis*</Text>
        </Document>
        <Document ID="4">
            <Title>Text and Formats</Title>
            <Text>Letter format

**Bold face**

*Italic face*

`literals`

Text with ^superscript^ and ~subscript~

Text with ~~strike out~~

Code block:
~~~python // ← this python thingy is optional, but might result in syntax highlighting
define foobar() {
    print "Welcome to flavor country!";
}
~~~

Text
Create lorum ipsum dummy text with 
\usepackage{blindtext}
\blindtext

</Text>
        </Document>
        <Document ID="5">
            <Title>Proprietary encodings</Title>
            <Text>I have implemented a few proprietary, quasi-MMD codes that are translated by Scrivener to particular Latex codes.
Quasi-MMD codes
Latex code
Implementation
[|text]
\mywordbox{text}
The text is formatted with a small box:
\newcommand{\mywordbox}[1]{%
  {% open a group for a local setting
   \setlength{\fboxsep}{-2\fboxrule}% the rule will be inside the box boundary
   \hspace{1pt}\fcolorbox{gray!20}{blue!5}{\hspace{2pt}\strut\textbf{#1}\hspace{2pt}}\hspace{1pt} % print the box, with some padding at the left and right
  }% close the group
}
[*text]
\index{text}text
With multiple passes of LaTeX, pdfLaTeX, LuaTeX, etc., text will become an entry in the index




</Text>
        </Document>
        <Document ID="6">
            <Title>Authors</Title>
            <Text>Choose between two YAML variants that can be processed by the latex template:

Variant 1: One sub name/affiliation for each author, as

author:  
- name: Paul Brandt  
  affiliation: Eindhoven University of Technology; Netherlands Organization of Applied Scientific Research TNO, Den Haag, The Netherlands   
- name: Twan Basten  
  affiliation: Eindhoven University of Technology, Eindhoven, The Netherlands 

Variant 2: One author only, as

</Text>
        </Document>
        <Document ID="7">
            <Title>Footnotes, Images and Links</Title>
            <Text>Footnotes

By anchor 

A footnote is a kind of anchor [^1] that refers to the actual text defined at the bottom of the page (or elsewhere in the text), like this:

[^1]: the text of the footnote that the anchor refers to. The anchor id can be anything, as long as the carrot symbol precedes the id, e.g., [^this_is_a_very_long_footnote_id]

Inline without anchor

This inline footnote ^[the text of the footnote is included at the position of the anchor] is defined without anchor. Like the anchored footnote, the position of the placement of the footnote in the document is defined by meta-properties.

Image inclusion
Define the image inline as ![image caption](path\to\image.png){#image-ref-label .class width=30 height=20px}

Or, use a short link in the text to indicate its position, such as:
![image caption][image-def-label]
And at the bottom of the page, include its definition with attributes. No matter how \cref{image-ref-label} is defined, you can always refer to its (type and) number with \(c)ref.

[image-def-label]: path\to\image.png "optional title" {#image-ref-label .class width=30 key2="val 2"}

Internal links
An explicit link has two parts, the link itself and the link definition, which may occur elsewhere in the document (either before or after the link).

* The link itself consists of link text in square brackets, followed by a label in square brackets. (There can be space between the two.): [text that will be given a click-able link] [the-label-of-this-link-source]
* The link definition consists of the bracketed label, followed by a colon and a space, followed by the URL, and optionally (after a space) a link title either in quotes or in parentheses, e.g., [my website]: http://foo.bar.baz (the link title)
* Use the automatically generated identifier (Extension: auto_identifiers)
	* See the [text about this link](#link-as-title-of-the-section).
	* Or, implicitly, see the [text about this link] as placeholder and below its definition

[text about this link](#link-as-title-of-the-section)

References to chapter numbers and images
This is not possible in MMD, currently. Some initiatives are being considered, though (REF). One way to solve this is to use latex code, as follows:

Blahbllah, see \cref{the-section-id-as-referenced-by-MMD}. This will produce: “Blahbllah, see Section 2.1”

Note the missing #-sign in the reference; the #-sign is an MMD-construct, not a latex construct. Furthermore, the cref (clever reference) package does not require the category to be named in the text (Section, Example, Chapter, Theorem, etc.), it will insert the correct one itself.

This works for other forms of references as well, i.e., anything that can be given a label, by the following label definition: \label{my-label-name}. Again, note the missing #-sign in the label definition.

External links
  Blahblah blah blah blah. See [my website][], or [my website].

[my website]: http://foo.bar.baz

footnotes (extension: footnotes)
Here’s a footnote reference [^1] and another.[^longnote]

[^1]: Here is the footnote.
[^longnote]: Here's one with multiple blocks.
    Subsequent paragraphs are indented to show that they
belong to the previous footnote.

        { some.code }

    The whole paragraph can be indented, or just the first
    line.  In this way, multi-paragraph footnotes work like
    multi-paragraph list items.

This paragraph won't be part of the note, because it
isn't indented.</Text>
        </Document>
        <Document ID="10">
            <Title>Tables</Title>
            <Text>Tables
Pipe tables
Pipe tables look like this:

| Right | Left | Default | Center |
|------:|:-----|---------|:------:|
|   12  |  12  |    12   |    12  |
|  123  |  123 |   123   |   123  |
|1|1|1|1

  : Demonstration of pipe table syntax {#anchor-for-its-reference}.

The syntax is the same as in PHP markdown extra. The beginning and ending pipe characters are optional, but pipes are required between all columns. The colons indicate column alignment as shown. The header can be omitted, but the horizontal line must still be included, as it defines column alignments. Since the pipes indicate column boundaries, columns need not be vertically aligned, as the last row indicates.
The cells of pipe tables cannot contain block elements like paragraphs and lists, and cannot span multiple lines, nor wrap text within cells.

Grid tables look like this:
: Sample grid table.

+---------------+---------------+--------------------+
| Fruit         | Price         | Advantages         |
+===============+===============+====================+
| Bananas       | $1.34         | - built-in wrapper |
|               |               | - bright color     |
+---------------+---------------+--------------------+
| Oranges       | $2.10         | - cures scurvy     |
|               |               | - tasty            |
+---------------+---------------+--------------------+
The row of =’s separates the header from the table body, and can be omitted for a headerless table. The cells of grid tables may contain arbitrary block elements (multiple paragraphs, code blocks, lists, etc.). Alignments are not supported, nor are cells that span multiple columns or rows. 

Multiline tables
Multiline tables are also possible, and allow headers and table rows to span multiple lines of text (but cells that span multiple columns or rows of the table are not supported). Here is an example:
-------------------------------------------------------------
 Centered   Default           Right Left
  Header    Aligned         Aligned Aligned
----------- ------- --------------- -------------------------
   First    row                12.0 Example of a row that
                                    spans multiple lines.

  Second    row                 5.0 Here's another one. Note
                                    the blank line between
                                    rows.
-------------------------------------------------------------

   : Here's the caption. It, too, may span
multiple lines.

These work like simple tables, but with the following differences:
	●	They must begin with a row of dashes, before the header text (unless the headers are omitted).
	●	They must end with a row of dashes, then a blank line.
	●	The rows must be separated by blank lines.
In multiline tables, the table parser pays attention to the widths of the columns, and the writers try to reproduce these relative widths in the output. So, if you find that one of the columns is too narrow in the output, try widening it in the markdown source.
Headers may be omitted in multiline tables as well as simple tables</Text>
        </Document>
        <Document ID="8">
            <Title>References</Title>
            <Text>References are based on bibtex. To specify a bibliography file use *--bibliography &lt;myCitations.bib&gt;* at the command line, or, the YAML metadata field *bibliography*.

Citations go inside square brackets and are separated by semicolons (note that NO SPACES surround the semicolon). Each citation must have a key, composed of ‘@’ + the citation identifier from the database, and may optionally have a prefix, a locator, and a suffix. Examples:

* Blah blah [see @doe99, pp. 33-35;also @smith04, chap. 1].
* Blah blah [@doe99, pp. 33-35, 38-39 and *passim*].
* Blah blah [@smith04; @doe99].

The citation identifier may contain special characters.</Text>
        </Document>
        <Document ID="9">
            <Title>Bullits and numbered lists</Title>
            <Text>Bullits and numbered lists

Bullit lists

The bullets need not be flush with the left margin; they may be indented one, two, or three spaces. The bullet must be followed by whitespace, and preceded by a blank line. A list item may contain multiple paragraphs and other block-level content. However, subsequent paragraphs must be preceded by a blank line and indented four spaces or a tab. 

  * Fruits

    Continued paragraph belonging to Fruits.

List items may include other lists. In this case the preceding blank line is optional. The nested list must be indented four spaces or one tab:

* fruits
    + apples
        - macintosh
        - red delicious

Number lists

Ordered lists work just like bulleted lists, except that the items begin with enumerators (numbers themselves are ignored) rather than bullets:
2. First item
1. Second item
21. Third item

Autonumbers

(@one)  My first example will be numbered (1).
(@)  My second example will be numbered (2).

Explanation of example (@one).

(@)  My third example will be numbered (3).</Text>
        </Document>
        <Document ID="11">
            <Title>Glossary</Title>
            <Text>Unfortunately, there is as of yet no representation of definition of glossary terms. One definition has been suggested:
[^glossaryfootnote]: glossary: term (optional sort key)
    The actual definition belongs on a new line, and can continue on
    just as other footnotes.
This would allow for footnotes to be specified as glossary terms. The *term* is the item that belongs in the glossary. The *sort key* is optional, and is used to specify that the term should appear somewhere else in the glossary (which is sorted in alphabetical order).</Text>
        </Document>
        <Document ID="12">
            <Title>Math</Title>
            <Text>Mathematical formulae are not possible in MMD. To that end, apply LateX rules and include appropriate libraries in the latex template, see also https://en.wikibooks.org/wiki/LaTeX/Mathematics. The suggestions below are not MMD cheats but LateX cheats instead.

\usepackage{mathtools}

Mathmode: 

* Inline: TEXT encompassed with \( ... \) of $ ... $
* Paragraph: wat was dit ook alweer?

If you are typing text normally, you are said to be in text mode, but while you are typing within one of those mathematical environments, you are said to be in math mode that has some differences compared to the text mode:
	1.	Most spaces and line breaks do not have any significance, as all spaces are either derived logically from the mathematical expressions, or have to be specified with special commands such as \quad
	2.	Empty lines are not allowed. Only one paragraph per formula.
	3.	Each letter is considered to be the name of a variable and will be typeset as such. If you want to typeset normal text within a formula (normal upright font and normal spacing) then you have to enter the text using dedicated commands.
	4.	The caret (^) character is used to raise something (superscript), and the underscore (_) is for lowering (subscript). If more than one expression is raised or lowered, they should be grouped using curly braces ({ and }).


$\mathpzc{ALC}$
</Text>
        </Document>
        <Document ID="13">
            <Title>Definitions, proofs etc</Title>
            <Text>Definitions, Theorems, Proofs and more are not possible in MMD. To that end, apply LateX rules and include appropriate libraries in the latex template, see also https://en.wikibooks.org/wiki/LaTeX/Theorems. The suggestions below are therefore not MMD cheats but LateX cheats instead.

\begin{mmdef}[definitie onderwerp]\label{def:my-unique-reference}
Here is a new definition
\end{mmdef}

\begin{mmexmp}\label{ex:my-unique-reference}
Here is a new example
\end{mmexmp}

\begin{mmdp}[My first design principle]
\end{mmdp}

\begin{mmprf}
Write your proof
\end{mmprf}

\begin{mmthrq}\label{:rq:my-unique-reference}
Here is a new research question
\end{mmthrq}


## KNOWN BUG ##

Unfortunately, the MMD format, e.g., MMD-lists, does not work within a Theorem environment, and we need to make use of Latex command. For instance, include a list in the Definition envionment as follows:
\begin{mmdef}
My definition includes the following items:
 \begin{enumerate}[label={-}]
   \item here is the first item
   \item Here is the second item
 \end{enumerate}
\end{mmdef}

Note that the indentation is only for maintaining an overview of the number of \begin{}-\end{} pairs 

## LaTeX header definition ##
These definitions/proofs/etc. are based on a package for theorems, i.e., amsthm. Before the above definitions/proofs/etc can work, we need to import and configure the Theorem package. This requires a LaTeX header definition, as follows:
\usepackage{amsthm}

\newtheorem{mmexmp}{Example}[section]
\newtheorem{mmthrq}{Research Question}
\newtheorem{mmdef}{Definition}</Text>
        </Document>
        <Document ID="20">
            <Title>Abstract</Title>
            <Text>*Background:* Access-and-Play semantic interoperability (sIOP) is the next glass ceiling in IT-based business collaboration. Current approaches towards sIOP rely on conventions on the semantics of the exchanged terms, which can be considered accepted folklore. Approaches to break through the ceiling require some level of automation, and artificial intelligence (AI) can make a difference.       
  
*Objective:* The objective of this study is to identify and define AI-based fundamental guidance towards access-and-play sIOP in contemporary architectural paradigms.  
  
*Method:* Our approach is based on the discipline of semiotics. We identify semiotic shortcomings in architectures, establish a semiotic explanation on software semantics and, subsequently, on sIOP. Based on these considerations, we develop guiding architectural principles in support of software semantics and sIOP. We evaluate these principles by designing and formulating an ISO-42010 Architecture Viewpoint and View on sIOP.   
  
*Results:* The semiotic approach demonstrates semantics in software to be the result of a reciprocity between data and the software code that operates on them. Data exchange breaks that reciprocity and the main concern of sIOP is to re-establish a valid reciprocity. Loosely coupled semantics, semantic alignments and an ontological commitment of the modelling language can be considered the cornerstone to achieve sIOP. The supporting principles are (i) semantic transparency, (ii) semantic separation of concerns, and (iii) explicit computational semantics. The resulting ISO-42010 Architecture Viewpoint and View on sIOP, including a semantic mediation capability, can be considered a pattern to consolidate sIOP in contemporary architectural paradigms.  
  
*Conclusions:* The major shortcomings in architectural paradigms to account for sIOP are their negligence of semiotic fundamentals and the absence of an explicit ontological commitment that stands at the root of semantics. By their explicit inclusion, access-and-play sIOP can be consolidated in contemporary architectural paradigms.   
</Text>
            <Comments>brandtp, 9/14/2018 We formulate more principles than these 3</Comments>
        </Document>
        <Document ID="21">
            <Title>Introduction</Title>
            <Text>Never before, data were so ubiquitous, and managed access to external data was so easy. Because current ICT is unable to *use* all that same external, non-native data as access-and-play service, agility in business collaboration is hampered in all domains. For instance, consider the following (allegedly real) example of an interoperability failure.

&gt; A German steel producer upgraded its industrial process robot. Since the majority of the steel production process is dependent on time, from a security point of view the decision was made to not rely on their own internal clocks but to use the German *Braunschweig Funkuhr* time radio signal as source for the exact time instead. At the end of April 1993, when Germany went on summer time, the computer clock of the steel producer went from 1:59 AM to 3:00 AM in one minute. This resulted in a production line allowing molten ingots to cool for one hour less than normal. When the process controller thought the cooling time had expired, his actions splattered still-molten steel, damaging part of the facility.

In this simple example a tiny difference in the meaning of `time` between the steel producer and the national time provider hampered interoperability to the extend of damaging the steel facility. This tiny difference rooted in the assumption by the steel producer that `time` expressed a continuous scale whilst for the Braunschweig Funkuhr, `time` denoted instant clock time for that time zone and therefore represented a non-continuous scale. In order to achieve that both collaborators, here the Braunschweig Funkuhr and the steel producer, can actually *use* their peers data, the need exists to design and implement wrappers that remove any inconsistency between the variations that may occur in terms, structures, dimensions and what have you. Many such variations exist, leading to a range of failures in so-called *semantic interoperability* (sIOP) and Section/Appendix ## provides for a short overview of sIOP-faults. Unfortunately, it is fundamentally impossible to automate the production of wrappers, because we need a genuine *understanding* upfront, which computers still cannot do.

The most disconcerting consequences of a lack of (automated) sIOP are time-to-deliver, flat interoperability failures, and even seemingly correct but quite invalid data analysis probably leading to faulty system behaviour. Current sIOP implementations are essentially based on the (time-consuming) process of establishing a (local) convention on the semantics of the terms that are exchanged during collaboration, requiring custom solutions and collaboration-dependent software adaptations. Such conventions can be considered a semantic monolith, which makes dealing with data outside the monolith impossible, unless again a time consuming (months) semantic adoption process is applied. Moreover, these semantic conventions consider semantic heterogeneity as a bug instead of a feature necessary to achieve semantic accuracy. But still, this conventions-based approach towards sIOP is accepted folklore in ICT. In view of the large uptake of the Internet, the Internet of Things (IoT), cloud computing and big data, and in view of economical pressure to intensify enterprise collaboration, we consider this approach "too little, too late". Some form of automation is required to resolve these issues, and we place artificial intelligence (AI) at its core. With the separation [coined by @Searle:1980hw] between strong AI (a system that can *think* and has a *mind*, in the philosophical definition of the term) or weak AI (a system that can only *act* like it thinks and has a mind), we take the position that --unfortunately-- strong AI is not yet available, if ever [@XiuquanLi2017]. We therefore make do with weak AI and show that despite its limitations it still has got a fundamental role to fulfil as carrier for semantics and sIOP, both facilitating the required automation. Weak AI, despite its current applications in Semantic Web or ontologies, has not yet been embedded in contemporary software architectural paradigms.  

In comparison, scalability was a big architectural concern in the past, requiring custom solutions as well. In response to this concern, scalability was standardised in the form of architectural patterns, and finally totally embedded and hidden into the infrastructure. Similarly, sIOP can be considered the architectural concern of this decade. We first need to provide a standardised solution pattern to address semantic concerns before we can embed it in a technological infrastructure. Only then we can claim that sIOP becomes transparent to the developer and that the semantic monolith is taken down. Where scalability resulted in a huge increase in performance-demanding applications against a fraction of the original costs and effort, business agility will emerge once the semantic monolith is removed and semantic services exist at the infrastructural level. Then sIOP becomes an access-and-play operation that can be achieved with data not anticipated for during software design in due time, at any point in their life cycle. Metaphorically speaking, we consider sIOP as a bridge overarching a (semantic) gap: with *bridgeheads* (semantic concerns) on each side of the gap, with a *spanning* (semantic aligments) resting on them to structurally support the bridge and its traffic, and with a *roadway* (data mediation) enabling the crossing of the traffic. Finally, architectural *principles* provide the necessary guidance to the architect for the various design decisions that effectively result in a particular bridge over a particular (semantic) gap. Our contributions to consolidating semantic interoperability in software architectures are fivefold, and represented as architectural principles and concerns, as follows:

* Semantic concerns (bridgehead): Abstracting semantics from a tacit software implication into a tangible, computational and distinct artifact provides us with the potential to connect to it and to make comparisons with the semantic artifact of the peer software agent. Based on the discipline of semiotics, we explain why semantics are irrelevant to software. Instead, we should focus on the reciprocity between data and the data processing code of software. This explains, too, the shortcomings of the current approach towards software semantics that rely on prescriptive information models. We argument that the application of ontologies and ontological commitment are fundamental to remedy current semantic shortcomings (\cref{bridgehead-semantics});
* Weak AI concerns (spanning): Since “strong AI” does not yet exist, sIOP remains in demand of human intervention in order to reconcile the semantic differences between collaborating software agents. However, human intervention is time consuming. We reduce the necessary human intervention to complement weak AI to a task that suffices to achieve sIOP, viz. authoring semantic alignments only (\cref{spanning-alignments});
* Mediation concerns (roadway): We provide for a prototypical implementation of a mediator as the necessary component to automatically translate data when transferred between the collaborating software agents (\cref{roadway-mediation});
* Principles: We base sIOP on establishing loose-coupling at the semantic level by introducing principles on semantic separation of concerns and semantic transparency (\cref{siop-principles}), and show how these principles can be operationalised;
* ISO42010 Architecture Viewpoint: We verify the applicability of the above concerns and principles by formulating their architectural consequences as a specific ISO42010 sIOP Viewpoint, and we show their proper position in the total architecture as corresponding sIOP view. As ISO42010 is considered a set of best practises for architecture description, and therefore is used with architecture frameworks such as MoDAF, TOGAF, DoDAF, RM-ODP and so on, we conclude that our sIOP Viewpoint and View can be considered to consolidate sIOP for contemporary architectural paradigms (\cref{iso42010-viewpoint-on-siop}).

Based on these contributions we defend that access-and-play sIOP can be embedded and hidden in infrastructural services when considering semiotic fundamentals and adding loosely coupled formal semantics to contemporary architectural paradigms. To that end, we first describe the semiotic fundamentals in \cref{the-semiotic-and-philosophical-foundations-of-semantics}.

</Text>
            <Comments>brandtp, 9/5/2018 We can apply another example, I’m open to that. Indeed a TOOP example could be appropriate. However, I cannot think of one but maybe Eric can?
Source: http://catless.ncl.ac.uk/Risks/14.57.html#subj1, accessed May 20, 2018
brandtp, 9/5/2018 Add sIOP-faults as appendix.</Comments>
        </Document>
        <Document ID="14">
            <Title>Proper English </Title>
            <Text>Some often made mistakes…
</Text>
        </Document>
        <Document ID="22">
            <Title>The semiotic and philosophical foundations of semantics</Title>
            <Synopsis>Purpose of this section: To establish an informal but concrete notion on (i) the semiotic triangle and the relationsbetween its nodes, and (ii) ontological commitment and its relation to modelling languages.

\end{synopsis}

</Synopsis>
        </Document>
        <Document ID="15">
            <Title>-ise/ -ize</Title>
            <Text>In British English, most words ending in -ise can also be spelt with ize. Exceptions are words in two syllables, e.g., surprise, and advertise and analyse. Therefore, in BE play safe and consistently use -ise. In American English, only -ize is used. 

* In Americal English, final -l is not usually doubled in an unstressed syllable, whilst in British English it is, e.g., US traveler, leveling, becomes GB traveller, levelling; hence, modelling
* Some endings in -ter in AE become -tre in BE: US theater, center become GB theatre, centre.
* Some endings in -or in AE become -our in BE: US labor, color become GB labour, colour.
* Some endings in -og in AE become -ogue in BE: US catalog, analog become GB catalogue, analogue.
* Some endings in -ense in AE become -ence in BE: US defense, offense, pretense become BE defence, offence, pretence. However, US practice becomes GB practise.

&lt;!-- einde opsomming --&gt;</Text>
        </Document>
        <Document ID="30">
            <Title>Expicit sIOP by alignments</Title>
            <Synopsis>Thus:

\begin{enumerate}
\item Follow the coherence principle and conclude that the models from which *external* data and *receiving* data processing code are derived, need to be brought into coherence with each other.
\item The coherence principle already enforced a single unique reference for each agent. Re-installing coherence demands a semantic alignment between those single unique references. 
\item The purpose of that alignment is to establish how the truth of expressions that are formulated in terms of agent A, can be estabished by using formulations in terms of agent A' against the single unique reference from A'. 
\item The language that is used for expressing the alignment should be fit for its purpose. Refer to EDOAL [@Scharffe2011] as the currently most complete one.
\end{enumerate}

\end{synopsis}</Synopsis>
            <Text>



![The three semantic concerns are related: conceptual modelling, semantic reconciliation, and semantic mediation][def:3Concerns]


&lt;!-- page additions --&gt;
[def:3Concerns]: src\images\3SemanticConcerns.png {#fig:3Concerns width=495px height=693px} 
</Text>
        </Document>
        <Document ID="16">
            <Title>That versus which</Title>
            <Text>
* “that/who” (no comma) is used to single out (restrict) from many possibilities the one and only that is referred to: 
    * The painting that was hanging in the foyer was stolen --&gt; from all paintings in the house, one hung in the foyer and that particular one was stolen;
    * The suspect who has red hair committed the crime --&gt; from all suspects indeed the perpetrator was the only red haired person;
* “, which /, who” (with comma) is used to add incidental information (unrestricted) about the subject that is referred to, however, not to single it out:
    * The painting, which was hanging in the foyer, was stolen --&gt; many paintings were hanging in the foyer, and the one that was stolen was one of them;
    * The suspect, who owns a red car, committed the crime --&gt; although the perpetrator owns a red car, this does not necessarily imply that from all suspects the perpetrator and only the perpetrator owns a red car. Any or all of the suspects might own a red car.
* hence, “who” refers to a restrictive clause while “, who” refers to a non-restrictive (informative) clause.

&lt;!-- einde opsomming --&gt;</Text>
        </Document>
        <Document ID="23">
            <Title>Semiotics</Title>
            <Synopsis>Present concrete notion on (i) the semiotic triangle and (ii) the relationsbetween its nodes.
Show abstraction/generalisation as stacking of triangles vertically, and representational meta-levels as stacking them horizontally.

\end{synopsis}
</Synopsis>
            <Text>The discipline of semiotics is the study of signs, reality and meaning. The meaning of a *token* (text, graphics, sound) ultimately relates to what it denotes in reality (the *entity*), whilst this relation cannot be deferred from the shape, structure or other characteristics of the token itself due to its total arbitrariness. De Saussure used a dyadic model, the ***semiotic sign***,that stressed that the token and the entity in reality were as inseparable as the two sides of a piece of piece of paper (Saussure 1959). This ‘self-containment of the sign’ remains one of the major principles of semiotics. Constructing the semiotic sign from its distinct parts is called ***semeiosis***. The token, in combination with their ability for semeiosis, provides humans with the tool to converse with each other. Semantics, then, emerges as a result of the semeiosis that connects the distinct parts of the inseparable semiotic sign.

Sanders Peirce (in: Sowa 2000) developed a triadic model of the semiotic sign, the semiotic triangle: a representamen (the token), an object (the entity), and the interpretant which expresses the mental and, hence, individual sense making (Figure 2.1(a)). The semiotic triangle was used and modified by Ullmann (Ullmann 1962), Ogden and Richards (Ogden and Richards 1989)and many others, also in recent years (Kuhn 2009). We introduce our modifications, as depicted in Figure 2.1(b), which mainly focus on naming conventions in IT architectures, as follows.


![The triadic model of the semiotic sign, according to Peirce (a), and modified by us (b). Example (c) shows the concept of a cat named “Yojo”][def:semtriangles]

We prefer the use of *entity* due to the ambiguous nature of *object* in IT. We consider an entity to stand for a thing or event, but also a category of entities, a relation between entities and a property of an entity. We refer to the *interpretant* component as the *conceptualisation*, to underline the individual conceptualisation that is being formed during requirements analysis and conceptual modeling. And we prefer *token* over *representamen*, and consider it both an atomic element and a particular composition of atomic elements. We include denotations for the edges that are connected to the conceptualisation vertex, and names that underline the individual and mental nature of the sense making. These names are directional, and must be read as the transformation that takes place in that direction. Finally, we add the causal characteristics that the edges represent, introduced by [@Ogden1989], as *adequacy*, *correctness* and *trueness*. The connection between the token and the entity is a dashed line because its existence is indirectly only through the conceptualisation and does not exist in any direct means. With “sign” we mean the semiotic self-contained sign. A well-known example of a sign is depicted in \cref{fig:semiotic-triangles}(c): when we talk about “Yojo”, our cognition interprets it as our cat. 

![Linking triadic models together.][def:linkedtriangles]

Multiple triangles can be linked together in various ways [Peirce in: @Sowa:2000di]. By stacking them together (\cref{fig:linked-triangles}(a)) a conceptualisation is made of “representing an entity”: the original concept of a [|cat] named “Yojo”(\cref{fig:semiotic-triangles}(c)) is being conceptualised as the concept of a [|cat named “Yojo”] and represented by [|cat:Yojo]. Eco [@Eco1976] uses the term *unlimited semeiosis* for the succession of stacking signs that emerge from that, ad infinitum. We consider unlimited semeiosis as addressing a dimension of comprehension about abstraction and generalisation, with an eventual finish in the ultimate [|Thing] concept. 

Linking the triangles horizontally results in different representational meta-levels, depicted in \cref{fig:linked-triangles}(b): From right to left, the characters “Y” “o” “j” and “o” are conceptualised as a single [|word] and represented as “Yojo”, which is conceptualised as a [|name] and represented as “name:Yojo”, which is conceptualised as an [|identifier] that might be represented as “Id=’name:Yojo’ ”.    

&lt;!-- page additions --&gt;
[def:semtriangles]: src\images\SemioticTriangles.png {#fig:semiotic-triangles width=600px height=200px}
[def:linkedtriangles]: src\images\LinkedTriangles.png {#fig:linked-triangles width=600px height=230px}</Text>
        </Document>
        <Document ID="17">
            <Title>Plural versus possessive -s</Title>
            <Text>Source: https://umanitoba.ca/student/academiclearning/media/Plural_vs_Possessive_S_NEW.pdf

**Plural**

* The most common way to pluralize a noun is to simply add an -s at the end:
    Hamburger (singular) becomes hamburgers (plural)\\
    College (singular) becomes colleges (plural)
* Nouns that end in a vowel followed by a -y take an -s in the plural:
    Monkey (singular) becomes monkeys (plural) \\
    Nouns that end in a consonant followed by a -y undergo a more dramatic change. First, the -y changes 
to an -ie and then an -s is added:
    Baby (singular) becomes babies (plural)
* Nouns that end in a sibilant (s, x, z, ch, sh) pluralize by adding an -es:
    Church (singular) becomes churches (plural)
* Nouns that end in an -is are replaced by -es in the plural:
    Thesis (singular) becomes theses (plural)
* Count nouns that end in -f pluralize by changing to a –ves:
    Calf (singular) becomes calves (plural) 

**Possessive**

* The possessive -s is used to show belonging: \\
    Kevin’s coat
* Add an ’s to the plural forms of nouns that do not end in -s: \\
    The children’s bedroom
* Add an ’ to the plural forms of nouns that end in -s: \\
    The addicts’ support group \\ 
    The seven Von Trapp kids’ singing nanny
* Apostrophes should not be used with possessive pronouns (my, yours, hers, his, its, ours). These 
Pronouns do not need apostrophes because they inherently show possession.
* It’s is a contraction for “it is” and its is the possessive pronoun that signifies “belonging to it”. 

&lt;!-- einde opsomming --&gt;</Text>
        </Document>
        <Document ID="31">
            <Title>Roadway: Mediation</Title>
            <Synopsis>Purpose of this section: Establish requirements for a *generic* mediator.

With mediation we denote the process of transcribing a data term that originates from Agent A into a data term that matches a term familiair to Agent A', based on both agents' ontologies and the alignment between them. The main issue here is that although many different types of relation can be defined between the concepts of ontology A and A', e.g., superset of, a transcription of a token from A into a token from A' is a complete replacement and, hence, implements an equivalence relation. In [@Brandt2018b], we show a semantic valid transcription process. The requirements of a mediator are:

\begin{enumerate}
\item Being a generic service
\item Fully defined by two ontologies and their alignments
\item Allows for semantic valid transcriptions only, where 'validity' refers to absence of inducing phantom semantics.
\item Appropriate behaviour for non-translatable content, which should apply only as result of an incomplete alignment, a logical incorrect alignment, or attempts to communicate content that is considered irrelevant for the receiving agent.
\end{enumerate}
\end{synopsis}</Synopsis>
        </Document>
        <Document ID="24">
            <Title>Ontological commitment</Title>
            <Synopsis>Purpose of this section is to show the relevance of a (modelling) language: a language is used to convey distinctions. The distinctions that are aticulated by a language are denoted as its ontologcal commitment. Modelling languages need to show distinctions that are of relevance to the purpose of modelling. The predominant purpose of modelling is to describe (a particular domain in) reality by distinguishing the entities of interest. The ontological commitment for a modelling language therefore should be of ontological nature, “(...) not in order to know *what there is*, but in order to know what a given remark or doctrine, ours or someone else’s, *says* there is” [@Quine:1953er]. The ontological square or its extension into the ontological sextet [describe it] can be considered the most basic one, which have been specialized into several flavours, all called upper-level, or top-level, or foundational, ontologies, e.g., UFO, BFO, DOLCE and more. 

Show how MDE/MDA applies an ontological commitment as defined in M3, which facilitates an equivalent distinction as the ontological square, but less than the ontol.sextet.
 
Optionally, provide for the distinctions/theories that are foundational to the two most appropriate ontological commitments / foundational ontologies: BFO and UFO.
\end{synopsis}</Synopsis>
            <Text>A (modelling) language is used to convey distinctions. The predominant purpose of modelling is to describe (a particular domain in) reality by distinguishing the entities of interest. The distinctions that are thus articulated by a language are denoted as its ontological commitment. The ontological nature of the commitment is characterised by: “(...) not in order to know *what there is*, but in order to know what a given remark or doctrine, ours or someone else’s, *says* there is” [@Quine:1953er].

For domain analysts, the resulting model (of the conceptualisation) represents the commitment that the domain users have about the entities that they consider relevant to discern: the domain commitment. In philosophy [@Bricker2016], similar questions are asked that relate to “life, the universe and everything” as opposed to a single domain of application: What *kind* of entities exist? Are the universal aspects that seem to be shared between individual entities, e.g.weight, taken to be sui generis? These are questions of ontology. From a more pragmatic view these questions can be asked in a more constrained, methodological nature: What kinds of entity exist according to a given theory or discourse? This is meta-ontology and the answers provide a generic framework of distinction that represents a useful meta-model to the domain analyst, denoted the ontological commitment.   

The ontological square [@Lowe2006b] can be considered the most basic ontological commitment. It is obtained by considering two formal but independent distinctions: that between types (Universals) and individuals (Particulars); and that between characteristics (Properties) and their bearers (Substrates). The four resulting categories and their causal relations are depicted in \cref{fig:onto-square-and-sextet}(a). Its extension into the ontological sextet [@Smith2005] is just to acknowledge that at some point the influence of time should be incorporated as well (\cref{fig:onto-square-and-sextet}(b)).

 ja, jullie gebruiken ook zoiets (is niet OC, maar C) maar dat is te beperkt en niet gebaseerd op realiteit (filosofie) maar op engineering sec .they can not differentiate for example, between the cup and the coffee that is holds.  of zo

Clearly, similar formal distinctions can be observed in contemporary modelling paradigms at their uppermost meta-level: OMG’s MOF M3 metametamodel distinguishes between the Association and the Class, while the Resource Description Framework’s language distinguishes primarily between a subject, an object, and the directed property relation between them. All these ontological commitments are very generic, intended to be applicable for all circumstances. Unfortunately, being very generic, the ontological commitments remain very sparse regarding their capability as a language to distinguish; for all examples above, it is impossible to differentiate, for example, between the cup and the coffee that it holds, while intuitively, these are very different from each other. The more extended an ontological commitment becomes, the more it can distinguish as a language between things that we are interested in.  

![The ontological square (a) according to [@Lowe2006b], and its extension (b) producing the ontological sextet according to [@Smith2005].][def:osas]

The ontological sextet has been specialised into several flavours, all called { upper-level | top-level | foundational }^[Please select the term you like best.] ontologies, e.g., UFO [@Guizzardi:2015ky], SUMO, YAMAYATO, BFO, DOLCE and more, and with their similarities and differences between them [@Jansen2008]. Not all of them are intended to provide for a complete foundation (UFO, BFO); several are only facilitating (DOLCE), or the result of (YAMAYATO), research into particular philosophical theories. No matter the reason for their existence, they all assume a certain philosophical viewpoint with the purpose to accurately describe categories that exist in reality according to their viewpoint. 

We consider this the philosophical cornerstone for semantics: we can assess the semantic validity of any proposition if and only if the underlying ontological commitment can be referred to. Furthermore, any assessment towards semantic interoperability of two semantic theories cannot be made without an assessment of the similarity between their underlying ontological commitments. Note, however, that “We look to (…) Ontology not in order to know *what there is*, but in order to know what a given remark or doctrine, ours or someone else’s, *says* there is” [@Quine:1953er]. It then remains the responsibility of the (domain) analyst or ontology engineer to select the viewpoint that is most appropriate for its purpose, in order to select the modelling language that describes the types of things that exist in the domain of application the most accurate.


&lt;!-- page additions --&gt;
[def:osas]: src\images\OntoSquareAndSextet.png {#fig:onto-square-and-sextet width=500px height=250px}

</Text>
        </Document>
        <Document ID="32">
            <Title>sIOP Principles</Title>
            <Synopsis>Purpose of this section: 
\begin{itemize}
\item Show the semantic architecture as an additional layer that is orthogonal to current layers, expressing a separation of concerns between syntax and semantics (see [@Brandt:2013jh])
\item Define loosely coupled semantics as a result of applying the 2 principles 'semantic separation of concerns' and 'semantic transparency' (see [@Brandt:2013jh])
\item Repeat the Coherence Principle, the sIOP Coherence Principle, and the Ontological Commitment Principle, and show how they fit in the semantic architecture
\item Better structure informal text below, towards more Principle definitions.
\end{itemize}
\end{synopsis}</Synopsis>
            <Text>The main (business) requirement is to achieve sIOP as quickly as possible, with as minimal effort as possible, for collaborations that had not been foreseen and consequently could not be anticipated for during design time of the (two or more) software agents.

Consequently, the software agents have been developed totally and completely independent from each other. This raises the following semantic concerns:

1. Loosely coupled semantics:
    i. Define semantics once during software design phase, and achieve sIOP many times with many different peers
    i. EW Dijkstra: Connected but as independent as possible. In its original reading this implies only defining the *what* but leaving the *how* transparent. For semantics the implication is a more abstract one: the semantics of what is being communicated shall remain transparent to *how* it is represented. More specifically, agents shall rely on an external oracle that can change the semantic vehicle from its original source native representation to the destined target representation, without changing the semantic cargo. Agents, then, can communicate in their own native representations without the need to learn or integrate their peers’ representations.
1. Scalable sIOP:
    i. Variable in number of peers
    i. Variable in level of semantic heterogeneity
1. Semantic concerns are foundational to sIOP (see \cref{fig:3Concerns} for three related ones):
    i. Explicit and computational semantics by *conceptual modelling*: Bridgehead 
    ii. Managed and controlled sIOP by *semantic reconciliation*: Spanning
    iii. Automated sIOP by *semantic mediation*: Roadway. Address semantic issue about the non-equivalence between an alignment and a transcription (refer to \cite{Brandt2018b})

*Ad. Dijkstra’s “Connected but as independent as possible”*. Complement weak AI with human brain:

 * use AI where possible (computational semantics for software agent; supporting semantic reconciliation)
 * use human brain where necessary (but not more): ontology engineering @ design time; alignment authoring @ pre-runtime

     
***Achieve loosely coupled semantics***
  
Loose coupling is founded on principles about (i) separation of concerns, and (ii) transparency:
   
* Principle *Separation of concerns*:
    * Classical: 
        i. Decompose system in parts
        i. with minimal functional overlap
    * Semantical:
        i. Separate your own semantics (i.e., conceptualisations, viz. let each software agent manage its own abstraction from reality)
        i. from establishing sIOP 
* Principle *Transparency*
    * Classical: 
        i. Agnostic to *how* its functions are being achieved
        1. Communicate with minimal mutual dependency
    * Semantical:
        i. Agnostic to *how* semantics are being achieved
        i. Communicate with minimal syntactic dependency, i.e., without agreements on semantic representation  


Formulate the principles in the format according to [@Greefhorst2011]

*Ad. semantic separation of concern*. Where in its classical application the result of applying the principle is that atomic functions are defined, designed and implemented only once and remain unique, in its semantic application the result of applying this principle is that every software agent maintains its own semantics. Semantics are, therefore, distributed all over the place. This seems counterintuitive or even plain wrong, however, it is necessary for complying with the concern about semantic scalability (in support of heterogeneous semantics). Besides that, it is a direct consequence of the demand to allow for independent software development

 * Principle: specify ontological commitment as basic 
 * Refer to (and partly reuse?) semantic architecture from [@Brandt2013], depicted in \cref{fig:sSoC}

![An architecture for loosely coupled semantics, founded on semantic SoC and semantic transparency [@Brandt2013]][def:sSoC]

 
***Achieve Scalable sIOP***

Ensure that different semantic topologies remain possible:
 
i. Star alignments (central domain ontology, aligned to local ontologies) for relative stable and homogeneous domain semantics
    * Good: easy semantic governance
    * Bad: very big semantic monolith, hence, low agility in dynamic environments
ii. Mesh alignments (bilateral alignments) for very dynamic and heterogeneous (domain) semantics, or low number of peers
    * Good: quickly established bilateral sIOP; granularity-on-demand, viz. intricate where necessary, coarse-grained where possible
    * Bad: complicated semantic governance
iii. Mix-n-Match (coarse-grained star-alignment with specialised bilateral alignments) for the 70% bulk 
    * Good: controllable semantic governance; after central alignment, quickly established bilateral sIOP
    * Bad: slightly more complicated mediation due to double alignment support



&lt;!-- page additions --&gt;
[def:sSoc]: src\images\SemanticSoC.png {#fig:sSoC width=448px height=426px} 

</Text>
        </Document>
        <Document ID="18">
            <Title>Progress &amp; Planning</Title>
            <Text>Because Scrivener (Windows) is not yet capable of calculating the target word count of a section from its subsections, the progress indicator is not very helpful in showing your actual progress. We can realise this by the use of excel.

To that end, you need to add two pieces of information to the scrivener meta-data:

1. Include a custom meta-data parameter, let’s call it ‘level’. The purpose of this parameter is to provide for the level of the section. Unfortunately, you have to fill this manually because the &lt;$hn&gt; placeholder tag (see Scrivener manual, Appendix D, Table D.2) is only effective on compiling, which has no use here. Use level = 1 for all first level scrivenings (document), etc.
2. Fill the Target parameter as you would expect, however, place a negative number for the section that needs to be calculated from its subsections, e.g., -1

Now export the “Outliner Contents as CSV”, and import it into Excel. Create in excel as many additional columns as levels and name them 1, 2, 3, 4, etc. Just the figure, no additional characters. Then, define in the cells for these columns the following formula’s:

Column 1: =IF($Q2=S$1,IF($Q3&gt;=S$1,IF($N2&gt;0,SUM(S3,$N2),SUM(S3,T3)),$N2),IF($Q2&gt;S$1,S3,0))
Column 2: =IF($Q2=T$1,IF($Q3&gt;=T$1,IF($N2&gt;0,SUM(T3,$N2),SUM(T3,U3)),$N2),IF($Q2&gt;T$1,T3,0))
Column 3: =IF($Q2=U$1,IF($Q3&gt;=U$1,IF($N2&gt;0,SUM(U3,$N2),SUM(U3,V3)),$N2),IF($Q2&gt;U$1,U3,0))
...
Last column: =IF($Q2=V$1,IF($Q3&gt;=V$1,IF($N2&gt;0,SUM(V3,$N2),V3),$N2),0)

And add one additional column that will give you the True Target (calculated) as:
Column TrueTarget: =IF(N2&gt;=0,N2,OFFSET(R2,1,Q2+1,1,1))

Explanation:
Columns 1, 2, 3 etc. will calculate the cumulative figures, from ground to top, for the level that is indicated by the name of the column. It does this from the following parameters (indicated for the first level):
* Q2 = your ‘level’ parameter
* S1 = the name of your column == the level that that column will cumulate
* N2 = the Target parameter (with negative numbers indicating the sections of interest)
* T3 = the previous level, the value of which represents the cumulative targets of the subsections



</Text>
        </Document>
        <Document ID="25">
            <Title>Bridgehead: Semantics</Title>
            <Synopsis>Purpose of this section: 
\begin{enumerate}
\item From a semiotic perspective, explain what we mean with semantics in software agents, i.e., the reciprocity between data and data processing code (both represented as Term from the semiotic Sign).
\item Establish that for representing semantics, descriptive models (i.e., ontologies) trump prescriptive models (all 42010 models).
\item Conclude that ontologies need their place as single point of reference (trueness) in architectures, and identify their relationship with the rest of the architectures, i.e., all other prescriptive models. Note the issue on Open World Assumption (ontologies) and CWA (prescriptive models).
\end{enumerate}

\end{synopsis}</Synopsis>
            <Notes>Argument:


1. The reciprocity between code and data manifests itself as software semantics
    1. The relationship between Data and Code is very closely coupled in order to maintain consistency between each other. Inconsistency results in software malfunction / crashes. Maintaining/controlling that consistency is one of the main goals of MDA/MDE.
    1. Inconsistency between Code and Data has either pragmatic grounds (i.e., code assumes different reality than data resulting in incorrect operations on the data) or semantic grounds (i.e., data assumes different reality than the code resulting in incorrect data being correctly operated on).
1. Explain shortcomings of 42010:2011 in terms of semiotic triangle:
    1. All models are representations of engineers’ conceptualisations
    1. In MDA, “models represent reality” makes the semiotic triangle conflate in a [|model] &lt;—[|representation]—&gt; [|reality] dimension, 
    1. This cuts-off the conceptualisation vertex and with that our “knowledge about our given remark or doctrine *says* there is”. We have removed the “ontological level” [@Guarino1994b], and with that, the fact that “terminological competence can be gained by formally expressing the ontological commitment of a knowledge base” (ibid.)
    1. (Meta-)model instantiation, and hence level transition, therefore remains at the Term/Model vertex
    1. The CIM models both semantics (Domain Model) and pragmatics (Business Model)
    1. Models are ultimately expressed as either Data or Code, both located at the Term/Model vertex.
    1. The trueness of prescriptive models, i.e., all 42010:2011 models, is established against their meta-models, while the trueness of descriptive models, i.e., ontologies, is established through the interpretation in the conceptualisation of reality (sets and set theory)
1. Clarify relationship/transition from ontologies to prescriptive system models
    1. Make use of [@Carraretto2012a]
    1. Note the issue on Open World Assumption (ontologies) and CWA (prescriptive models).
</Notes>
        </Document>
        <Document ID="40">
            <Title>Classeur source</Title>
            <Text>**Consolidating semantic interoperability in software architectures** Paul Brandt[^a]^,^[^b], Eric Grandy [^c], (Johan Lukkien[^a]), Twan Basten[^a]   
&gt; Next milestone to achieve: &gt; * Finalising the Title, Abstract and Introduction, and presenting it for review to co-authors</Text>
        </Document>
        <Document ID="33">
            <Title>ISO42010 viewpoint on sIOP </Title>
            <Synopsis>Consolidate the ideas on the bridgehead, spanning, roadway and principles into an additional ISO42010 Architectural Viewpoint (sIOP) that summarises all previous Sections as concerns on semantics and sIOP. ***Preferrably written by Eric.***

\end{synopsis}</Synopsis>
        </Document>
        <Document ID="19">
            <Title>meta-data</Title>
            <Text>---
title:  'Consolidating semantic interoperability in contemporary architectural paradigms'  
subtitle:   
author:  
- name: Paul Brandt  
  affiliation: Eindhoven University of Technology; Netherlands Organization of Applied Scientific Research TNO, Den Haag, The Netherlands   
- name: Eric Grandry  
  affiliation: Luxembourg Institute of Science and Technology, Esch-sur-Alzette, Luxembourg  
- name: Twan Basten  
  affiliation: Eindhoven University of Technology, Eindhoven, The Netherlands  
category:   
bibliography: src/bib/CitedByMe-2018_archSIOp.bib  
csl: templates/environmental-health-perspectives.csl  
abstract: |   
  
  *Context:* Access-and-Play semantic interoperability (sIOP) is the next glass ceiling in IT-based business collaboration. Current approaches towards sIOP rely on conventions on the semantics of the exchanged terms, which can be considered accepted folklore. Approaches to break through the ceiling require some level of automation, and artificial intelligence (AI) can make a difference.       
    
  *Objective:* The objective of this study is to identify and define AI-based fundamental guidance towards access-and-play sIOP in contemporary architectural paradigms.  
  
  *Method:* Our approach is based on the discipline of semiotics. We identify semiotic shortcomings in architectures, establish a semiotic explanation on software semantics and, subsequently, on sIOP. Based on these considerations, we develop guiding architectural principles in support of software semantics and sIOP. We evaluate these principles by designing and formulating an ISO-42010 Architecture Viewpoint and View on sIOP.   
  
  *Results:* The semiotic approach demonstrates semantics in software to be the result of a reciprocity between data and the software code that operates on them. Data exchange breaks that reciprocity and the main concern of sIOP is to re-establish a valid reciprocity. Loosely coupled semantics, semantic alignments and an ontological commitment of the modelling language can be considered the cornerstone to achieve sIOP. The supporting principles are (i) semantic transparency, (ii) semantic separation of concerns, and (iii) explicit computational semantics. The resulting ISO-42010 Architecture Viewpoint and View on sIOP, including a semantic mediation capability, can be considered a pattern to consolidate sIOP in contemporary architectural paradigms.  
  
  *Conclusions:* The major shortcomings in architectural paradigms to account for sIOP are their negligence of semiotic fundamentals and the absence of an explicit ontological commitment that stands at the root of semantics. By their explicit inclusion, access-and-play sIOP can be consolidated in contemporary architectural paradigms.   
  
...</Text>
            <Comments>brandtp, 9/14/2018 We formulate more principles than these 3; to be added</Comments>
        </Document>
        <Document ID="26">
            <Title>What is software semantics</Title>
            <Synopsis>The purpose of this section is to explain software semantics as the "reciprocity between data and software code", and show that to some extent, set theory can replace the conceptualisation node.
Conclude that the reciprocity between data and data processing code represents the smallest (atomic) semantic monolith.

Additionally, optionally, show:
\begin{enumerate}
\item the relationship with Grice's distinction in semantics as "what is said" and "pragmatic meaning": DONE
\item OO as initial implementation to consolidate this reciprocity, and the class as implementation of the atomic semantic monolith; 
\end{enumerate}

\end{synopsis}</Synopsis>
            <Text>We take the position that weak AI is essentially a token-based machine without the ability to close the gap between token and reality. Also called the Grounding Problem [@Harnad1990], addressing this fundamental issue in software engineering about semantics is at best extremely narrow [@Steels:2008tr], or not present at all [@Cregan2007]. This implies that the semiotic triangle is denied its conceptualisation vertex, and the sign remains incomplete. This is confirmed by the software engineering discipline herself implicitly, since it consistently speaks of ‘models that represent reality’ in a certain purposeful context without factoring the conceptualisation into the equation [@Aßmann2006]. Consequently, the edges that connect the conceptualisation remain vague or necessarily conflate on the relationship between the model and reality, depicted in \cref{fig:software-models-reality}. In terms of [@Quine:1953er] above, we have beheaded the sign and cut-off our “knowledge about our given remark or doctrine”, we deleted that what “we *say* there is”. We have removed the “ontological level” [@Guarino1994b], and with that our “terminological competence [that] can be gained by formally expressing the ontological commitment of a knowledge base” (ibid.). However, since we make do with weak AI and therefore with this beheaded sign necessarily, we must conclude that genuine semantics can not ever exist in current software agents.  

![Software engineering applies a beheaded semiotic triangle in which its edges remain vague or conflate in the single relation between model and reality.][def:softmodelsreal]

During the use of a software agent the semeiosis is taken care of by the human-in-the-loop, viz. the end user at the human-machine interface (HMI) whom interprets the tokens that are displayed (subjectivation). During development of a software agent the semeiosis is taken care of by another human-in-the-loop, viz. the software engineer whom implicitly performs the conceptualisation and explicitly represents this conceptualisation into tokens, i.e., *models*. Consequently, all models are representations of the engineers’ conceptualisations. From the many models that software engineering typically generates we focus on a pair of models that constitute the engineers’ semantics: the information or data models that refer to the *information entities* in reality, paired with the process or business models that represent the *event entities* that operate on the information entities. Data processing is in its bare form nothing more than tokens that follow a specific language grammar. This bare form is a representation of its quintessence, viz. a run-time notion on the proper way to operate on the data. Together, these models comprise the smallest atomic union that can represent meaning, indicated by [@Grice:1991BT] as a twofold: the semantic meaning, or “what is said”, and the pragmatic meaning, what we like to understand as “how it relates to our intentions”. 

\begin{mmdef}[Atomic semantic monolith]\label{def:atomic-semantic-monolith}
An Atomic Semantic Monolith (ASM) denotes the smallest, highest grained pair of models (a data model and a data processing model) that remains faithful to the entity in reality that it refers to.
\end{mmdef}

At the modelling level, semantics still exist by virtue of the designer. However, when the software agent is subsequently compiled, its binary code originate from the process model of the model pair (operations, algorithms), and the memory allocation for the data originates from the information model of the model pair (size, format, encoding). At this binary level the software engineer has left the building, and with her the conceptualisation vertex and the subsequent capability for semeiosis and, thus, semantics. In other words, at binary level we have lost the capability to verify the semantic coherence between the code and the data while the reciprocity between data and software code determines the semantic validity of the data processing. For instance, consider a data element $t$ to represent temperature, and a data algorithm to establish fever, e.g., `t &gt; 37.0` $\to$ `fever`. The one and only means to keep the software from failing is that both the data and the algorithm (i) are expressed in the same unit of dimension ($\si{\degree}C$ in this example), apply the same (ii) resolution and (iii) accuracy, to name a few obvious constraints. We, therefore, take the stance that semantics can only exist in software by virtue of the semeiosis by the human-in-the-loop, while in the software agent itself semantics are necessarily reduced to the reciprocity between data and software code. Still, the software agent acts as transport medium for the semantics as intended by the software engineer to the semantics as experienced by the end user at the HMI. We therefore consider the coherence between data models and data processing models essential for enforcing the software agent to maintain a semantic valid reciprocity between binary code and the data it operates on. 

This leads to the definition of a (normative [@Greefhorst2011]) design principle to its effect:

\begin{mmdp}[Semantic coherence principle]\label{dp:semantic-coherence-principle}

Establish explicit coherence between the models that are contained in a semantic monolith.

\textbf{Type of information:} business

\textbf{Quality attributes:} (semantic) accuracy, reusability, manageability, understandability 

\textbf{Rationale:}
\begin{enumerate}
\item Semantics in software agents are necessarily reduced to, and emerge from, the reciprocity between the data and the binary code that operates on them;  
\item Without explicitly addressing -- at modelling level -- \textbf{all} facets that influence the coherence between the data on the one hand, and the operations that apply on them on the other, the software agent cannot guarantee to maintain the reciprocity between them at the binary level;
\item Without maintaining the reciprocity between binary code and the data it operates on, the semeiosis performed by the end user on the result of the data processing and their subsequent semantics cannot be guaranteed to be similar as intended by the software engineer.
\end{enumerate}
\textbf{Implications:}
\begin{enumerate}
\item The coherence principle is a necessary condition for supporting semantic interoperability;
\item The scope of semantic validity \&amp; accuracy is addressed explicitly and can be referred to;
\item Reuse of data often implies reuse of the data processing code, and vice versa. Having established explicit coherence improves the quality of data and code reuse, and facilitates the verification that the scope of the semantic validity \&amp; accuracy applies in the new context as well;
\item manageability ...?
\item understandability ...?
\end{enumerate}  
\end{mmdp}
Coherence between models can be established with use of a single unique reference against which the truth of the expressions of both models can be verified. In semiotics, this single unique reference is considered reality, as indicated in \cref{fig:semiotic-triangles}(b) by the *trueness* characteristic. Except as toy example in [@Steels:2008tr], this is clearly not possible. The *correctness* characteristic is the only alternative left, taking the conceptualisation node as its principle point of reference, as depicted in \cref{fig:single-semantic-reference}(b). This is exactly what the mathematical branch of *formal semantics* achieves [@Gamut1991; @Genesereth:1987dg] with its three main characteristics, depicted in \cref{fig:single-semantic-reference}(a), viz. connecting (i) an abstract syntax of a language to (ii) a domain of interpretation (usually a set theoretic framework) by defining (iii) an interpretation function from the abstract syntax onto the set theoretic framework. In terms of the semiotic triangle, \cref{fig:semiotic-triangles}(b), this implies the following:

(i) the *representation* node represents models that can be formulated by use of an abstract syntax (and grammar) as its modelling language. In this reading, a model is a particular constellation of tokens that represent a particular state of affairs;
(ii) a particular *conceptualisation* can be mathematically formulated as a specific constellation of (unnamed) individuals, sets of individuals, and sets of sets; 
(iii) the *subjectivation* edge can be formulated as the interpretation function that assigns a mapping from modelling language tokens onto the set elements, enabling the evaluation of a specific model against the intended conceptualisation from (i). 

In this way, the cognitive quality of the conceptualisation can be substituted with set theory. Formulating the conceptualisation as a set theoretic model essentially remains a representation, albeit a mathematical one. One can argue that such substitution does not resolve the grounding problem, and appropriately so. Still, mathematics provide for a very exact way to express oneself, reducing the ambiguity that comes implicitly with any other language, and such mathematical constructs come as close to the conceptualisation as we possibly can get with a token-based machine. Furthermore, logical constructs used at the syntactical level can be interpreted into set theoretic operations, facilitating the evaluation of (complicated) expressions. Formal semantics thus provides a domain of discourse about a particular conceptualisation as principle point of reference for both the data model and the data processing model. The particular conceptualisation is then replaced with a particular Domain of Interest (DoI), and both subjectivation relations are replaced with their interpretation function on the abstract syntax of the models. 

![Maintaining the reciprocity between data and data processing models through a single semantic reference, viz. the conceptualisation (b), represented as DoI, viz. a selection of individuals with domain specific characteristics defined as sets (a).][def:ssref]

In conclusion, we explain software semantics as the reciprocity between data and software code, realised by maintaining the coherence between pairs of data and data processing models, by applying formal semantics to formulate a particular conceptualisation as a DoI that can act as semantic reference, and interpretation functions which perform the subjectivation from the data and operation models to that reference.

&lt;2nd Principle: Make the ASM as small as possible, but not smaller than required to express a semantic element. Too vague, yet. Not necessary to convey the primary message, imo.&gt;


&lt;Elaborate on OO to consolidate the reciprocity; take the class as example of a semantic monolith, the minimal, atomic one.&gt;

&lt;!-- page additions --&gt;
[def:softmodelsreal]: src\images\SoftwareModelsReality.png {#fig:software-models-reality}
[def:ssref]: src\images\SingleSemanticReference.png {#fig:single-semantic-reference}</Text>
            <Comments>brandtp, 8/30/2018 Make use of 42010 terminology
brandtp, 8/30/2018 ... ditto ...</Comments>
        </Document>
        <Document ID="41">
            <Title>Abstract</Title>
            <Text>*Background*: Many architectural principles exist in order to improve the efficacy and quality of software. Several software abilities, interoperability in particular, has been instrumental in the emergence of a wide variety of contemporary internet applications, e.g., IoT, Big Data and networked business operations. Never before, data were so ubiquitous. Never before, a managed access to external, non-native data has been so easy. Unfortunately, *using* that same external, non-native data shows extremely difficult: For a data consuming application, interpreting and using external data requires to adopt a sufficiently similar world view as the data provider assumed. This semantic part of interoperability represents a bleeding edge in software development, resulting in flat application failures or, more disconcertingly, in seemingly correct but quite invalid data analysis and use, and their correction always require a significant time and effort that shows a substantial impediment towards business operations and agility. Although technologies such as the Semantic Web and ontologies are available, and despite the principles and practices of the model driven architecture paradigm, no architectural guidance to semantic interoperability exists, neither in terms of architectural principles nor as design practices. *Objective*: The objective of this study is to identify and define the fundamental guidance towards semantic interoperability in contemporary architectural paradigms.  *Method*: We apply a design science approach and adopt their Information Systems Research Framework. We first identify shortcomings in architectural paradigms to account for semantic interoperability and formulate these as concerns, then develop architectural principles that follow from these concerns, and subsequently apply those to arrive at an architecture that prepares software with a capability for semantic interoperability.  *Results*: Based on fundamentals of software behaviour, we conclude that semantics in computer science can be considered the result of a reciprocity between data and the software code that operates on them. We analyze that the major shortcomings in architectural paradigms to account for semantic interoperability, is laid in their negligence of semiotic fundamentals and, particularly, the absence of an explicit ontological commitment that stands at the root of semantics and, hence, semantic interoperability. We show that corrective measures introduce three architectural principles in order to achieve loose coupling at the semantic level. We subsequently infer ***X*** architectural concerns, and suggest a means to their consolidation in view-based and model-driven architectural paradigms.  *Conclusion*: We propose architectural guidelines that provide software applications with the capability for semantic interoperability, without devaluation on existing software qualities or architectural concerns.</Text>
        </Document>
        <Document ID="34">
            <Title>Related work</Title>
            <Synopsis>Group the papers into 3 (?) categories, and discuss their strong and weak points in relation to sIOP and architecture in general, and our paper specifically.

\end{synopsis}</Synopsis>
            <Text>Discuss the following papers:

1. M. B. Almeida, C. P. Pessanha, and R. Barcelos, “Information Architecture for Organizations: An Ontological Approach,” in Ontology in Information Science, C. Thomas, Ed. IntechOpen, 2018, pp. 1–27.
2. S. Yang, J. Guo, and R. Wei, “Semantic interoperability with heterogeneous information systems on the internet through automatic tabular document exchange,” Inf. Syst., vol. 69, pp. 195–217, Sep. 2017.
3. U. Aßmann, S. Zschaler, and G. Wagner, “Ontologies, Meta-models, and the Model-Driven Paradigm,” in Ontologies for Software Engineering and Software Technology, C. Calero, F. Ruiz, and M. Piattini, Eds. Springer-Verlag Berlin Heidelberg, 2006, pp. 249–273.
4. C. Atkinson and T. Kühne, “The Essence of Multilevel Metamodeling,” LNCS, vol. 2185, pp. 19–33, 2001.
1. H. Carvalho e Silva, R. de Cassia Cordeiro de Castro, M. J. Negreiros Gomes, and A. Salles Garcia, Well-Founded IT Architecture Ontology: An Approach from a Service Continuity Perspective, vol. 294. Springer-Verlag Berlin Heidelberg, 2012.
1. R. Carraretto, “Separating Ontological and Informational Concerns : A Model-driven Approach for Conceptual Modeling,” Federal University of Espírito Santo, 2012.
1. C. L. B. Azevedo, M. E. Iacob, J. P. A. Almeida, M. J. van Sinderen, L. F. Pires, and G. Guizzardi, “Modeling resources and capabilities in enterprise architecture: A well-founded ontology-based proposal for ArchiMate,” Inf. Syst., vol. 54, pp. 235–262, 2015.
1. M. B. Almeida, C. P. Pessanha, and R. Barcelos, “Information Architecture for Organizations: An Ontological Approach,” in Ontology in Information Science, C. Thomas, Ed. IntechOpen, 2018, pp. 1–27.
1. D. Gasevic, D. Djuric, and V. Devedzic, Eds., Model Driven Architecture and Ontology Development. Springer Berlin Heidelberg New York, 2006. Particularly Part II: The Model Driven Architecture and Ontologies
</Text>
        </Document>
        <Document ID="27">
            <Title>Explicit semantics</Title>
            <Synopsis>The purpose of this section is to establish that for representing semantics, descriptive models (i.e., ontologies) trump prescriptive models (all 42010 models)

Firstly, describe that formal semantics can to some extend take the role as conceptualisation, and hence using set theory as conceptualisation is the best option we have to address semantics. Consequently, show that semantic ambiguity then "only" follows from 4 construction issues (already presented in text below).

Secondly, make the distinction between descriptive and prescriptive models [@Henderson-Sellers2012], and in [@Aßmann2006]: "Specification models focus on the specification, control, and generation of systems; ontologies focus on description and conceptualization (conceptual modelling) of things. Both kinds of models have in common the qualities of abstraction and causal connection."

Second argument shows that (i) the trueness of a model is laid in reality, which is impossible to achieve, and that (ii) the next best we can achieve is establishing the correctness of a model against its conceptualisation node. Finally, observe that (iii) 4 issues will influence the correctness of the model. Then conclude that the best tool to control these issues are the logics from descriptive models (viz. ontologies) at the one hand, and its use as ontological commitment for the prescriptive models (viz. the 42010 models)

Conclusions:
\begin{enumerate}
\item ontologies are more appropriate artefacts for conceptual models than system models
\item as in [@Aßmann2006]: "Specification models focus on the specification, control, and generation of systems; ontologies focus on description and conceptualization (conceptual modelling) of things. Both kinds of models have in common the qualities of abstraction and causal connection."
\end{enumerate}
\end{synopsis}</Synopsis>
            <Text>Once we have established a conceptualisation, it needs a representation because, despite being a mathematical representation, the sets and individuals in the DoI remain nameless. It is necessary to represent them in a (pair of) model(s) that is tangible, computational and a distinct artifact in order for the software agent to use it and, eventually, make comparisons with the semantic artifact of the peer software agent. We denote the model that represents a conceptualisation a *conceptual model*. The conceptual model that describes semantics best is a model that is as faithful to reality as possible. This begs the questions about the nature of a conceptual model and the nature of faithfulness. To start with the latter and as indicated in \cref{fig:semiotic-triangles}(b), we equate faithfulness with trueness between the representation and the entity in reality. Since this aspect is a characteristic of an indirect relationship, it can only emerge as a result of the adequacy and correctness characteristics. The former one concerns the conceptualisation aspect; in this section we address the correctness and show how differences can emerge between the conceptualisation and the model when constructing the latter. In literature, four construct issues are considered between a conceptualisations and its representation in a model, depicted in \cref{fig:construct-issues}. An exhaustive treatment can be found in [@Guizzardi:2005vt], see also [@CarvalhoeSilva2012; or @Azevedo2015].

![Four different types of construction issues that come with formal semantics. Which one is more clear: (a)[@CarvalhoeSilva2012] or (b) [@Azevedo2015]?][def:constructissues] 

The more precise the representation of the conceptualisation, the higher its comprehensibility appropriateness. Semantic accuracy improves when minimising the four construct issues:

* Construct overload, or non-lucidity, emerges when the interpretation function maps an element from the abstract syntax onto more than one element (individual, subset) from the conceptualisation: One token can mean more than one thing, e.g., [|bank];
* Construct excess, or unsoundness, represents an abstract syntax element that does not map onto an element from the conceptualisation: One token does not have a meaning at all;
* Construct redundancy, or non-laconicity, occurs when more than one abstract syntax element can be used to represent an element from the conceptualisation: More tokens mean the same, e.g., ...;
* Construct deficit, or incompleteness, specifies the situation where a conceptual element does not map onto a token: It is impossible to express a concept because the language has no token for it, e.g., [|....] (example intentionally left blank).

The best representation of a conceptualisation, then, is a model that is lucid, sound, laconic and complete, i.e., the interpretation/representation mapping is isomorphic. This is difficult to achieve, and due to the complete, accurate and complementary categories of how its carves-out the DoI, using the ontological commitment of the modelling language proves a useful tool in that respect.   

In contemporary architectural paradigms, models are being used as first class citizens to the architectures, MDA, IEEE-1471 and ISP RM/ODP alike. It is therefore imperative to decide upon the major characteristics of a model. The distinction between descriptive and prescriptive models is broadly accepted, where a prescriptive model is used to specify its subject, and a descriptive model is used to describe its subject. As explained by [@Gonzalez-Perez2007], this distinction only addresses how the model is being used and does not express a complementary, disjunct property. In stead, a genuine dichotomy emerges when considering the role that the model plays (ibid.). Then, a specification model generally takes a forward-looking role, specifying how the subject is supposed to be. A descriptive model, on the other hand, generally takes a backward-looking role and addresses the subject as it currently is, or once has been. In [@Aßmann2006], the relationship that a forward-looking model has with its subject is characterised as an instance-of relation, and that of a backward-looking model as an is-represented-by relation. Although we acknowledge the differences that exist, we consider both terms confusing when semiotics are involved since we cannot substantiate their suggested equivalence with the instantiation relation from the ontological square/sextet or the representation relation from the semiotic triangle. Instead, we observe that the characteristics of the refers-to relation will specialise into a declarative relation for a forward-looking model: The entity is deemed to follow the rules that are specified by the model. Similarly, for a backward-looking model that provides for a representation of “what a given remark or doctrine, ours or someone else’s, says there is”, the refers-to relation specialises into a descriptive relation. We thus observe that the refers-to relation is a causal relation, the direction of which is dependent on the model’s characteristic: declarative towards the entity for a forward-looking model, while descriptive towards the token for a backward-looking model. As a consequence, we conclude that for forward-looking models their truth lies in their meta-models, as depicted in \cref{fig:linked-triangles}(b). Mutatis mutandis, the truth for backward-looking models lies in the entities they describe. 


     
1. Explain: difference between ontologies and models
    i. Models lack an elaborate ontological commitment, domain ontologies naturally evolve on foundational ontologies (that express an ontological commitment)
    ii. For prescriptive models, truth lies in meta-models (good for deterministic behaviour); ontologies are descriptive models for which the truth lies in reality (good for semantics)
    iii. ontologies have open world assumption (semantic under-specification), models have closed world assumption (data remain consistent, good for performance)
    iv. Models specify systems, ontologies conceptualise reality (entities) 
    * Try to also connect the onto/model distinction with above principles 
    * Induced problem: from OWA (domain ontologies) to CWA (information/data models), viz. how to get closure?
    * Principle: use domain and business ontologies for “computational independent”-ish models [@Aßmann2006]
    * Bridge descriptive --&gt; prescriptive models by grounding all prescriptive model elements with concepts from descriptive model (see e.g. \cref{fig:OntosInMDE}).


In the remainder of this text we will refer to the formulation of the reference conceptualisation as a *conceptual model*.

![The use of ontologies in MDA, from [@Aßmann2006]][def:ontoMDA]

&lt;!-- page additions --&gt;
[def:ontoMDA]: src\images\OntosInMDE.png {#fig:OntosInMDE  width=568px height=346px}
[def:constructissues]: src\images\ConstructIssues.png {#fig:construct-issues  width=533px height=210px}
</Text>
            <Comments>brandtp, 9/19/2018 describe/explain the term
brandtp, 9/19/2018 find proper example</Comments>
        </Document>
        <Document ID="42">
            <Title>Introduction</Title>
            <Text>  
  
Concerning the grounding problem, since strong AI does not yet exists, and weak AI is not strong enough, the only tool to ground the terms from which semantics can emerge, therefore, remains the human brain that complements the shortcomings of weak AI. And that is exactly the current state of the art in software engineering: being aware of the application domain during design-time, the software engineer provides for the necessary semantics and assures, by means of their encoding in software constraints, schemata, class definitions and matching business and domain rules, that the particular software agent operates on the data in a way that is isomorphic to the reality the software agent is about. Although this may solve the grounding problem for the agent's native data, it does so by sacrificing the software agent's flexibility to process foreign data that commits to another grounding, a flexibility that is the essential condition to sIOP in general, and even more so for access-and-play sIOP. This would call for another solution to the grounding problem, but as just explained, we're "stuck" with weak AI that cannot resolve it differently. When we accept this implicit semantic rigidness of software agents, the question then becomes whether we can deal with the semantic rigidness in another way? Because one cannot deal with tacit knowledge, the assumption underlying the question is that semantics can be made explicit. Fortunately, the Semantic Web (SW) initiative at the one hand [@W3C2015], and the ontology engineering movement on the other [@IAOA2013], stimulate such explicit attention for semantics. We therefore can focus on the issue of semantic rigidness, and consider this question, and particularly its relationship with the SW and ontology technologies, as a software engineering issue that, by its generic nature, should be resolved at the level of architecture.  
 
* Contemporary solutions are investigated along three different reconciliation techniques [@Silva2007, @Hameed2004]: merging, alignment [@Balachandar2013, @Taye2010] and integration. The merging and integration techniques are characterized by their producing a new, unified world view from the existing ones. In contrast, the alignment technique brings the different views "(...) into mutual agreement, making them consistent and coherent" [@Hameed2004]. From an architectural point of view, the alignment technique brings about a significant higher form of *loose coupling* than the other two techniques. That is the precise reason why we defend to found sIOP on the former one and reject the latter techniques. Furthermore, although any design time reconciliation technique is contrasting with the *access-and-play* capability that we imply when we speak about sIOP, by introducing alignments, progress towards access-and-play is still being made: (i) required modifications are lifted from the implementation level to the configuration level; (ii) sIOP functionality can be abstracted and collected into a distinct component for reuse; (iii) designing and developing semantic mappings becomes a distinct and domain-independent engineering discipline with dedicated research, tooling and artifacts, and, finally, (iv) reconciliation has been recognized as a plausible solution for a long time [@Euzenat:2013ie]. What remains open, however, is its architectural perspective, notably about agreeing on the concerns that are pursued and the principles for their underpinning, the services that result, the standards that such services would require and the available initiatives that represent potential candidate standards. An architecture for sIOP should be designed to consolidate related architectural concerns about data re-use and independent application development for collaborating software agents, bringing secondary benefits on concerns about semantic maintainability and modifiability. Certainly, the semantic web initiative at the one hand [@W3C2015], and the ontology engineering movement on the other [@IAOA2013], stimulate explicit attention for semantics. Still, in order for (legacy) applications to respond, in ever decreasing time-spans, to ever increasing demands for collaboration, those explicit semantics need (i) to be brought into coherence with (extra-)functional aspects of the system and its components, (ii) to align with all data models and data representations as they occur in their many different forms in distributed systems, and (iii) to become synchronized with the system life cycle. In other words, semantics require to become properly and explicitly embedded into the architectures of the underlying systems and components. Only then we can claim to have coped with the semantic reminiscences of the monolithic beast and provide for semantic interoperability on an *access-and-play* bases.  
&gt; Dan de onderstaande teksten lezen, bekijken welke nieuwe probleemaspecten ze identificeren, en een korte samenvatting van elk geven als apart blokje   
&gt;Finally, insert overview of article, where possible combined for each section with shortcomings of related work.   
----  
The grounding problem in itself has another consequence in relation to the distributed nature of sIOP that we explain as follows. In essence, data are *encodings* about the state of affairs in that part of reality that the software is interested about. With the absence of strong AI, only the software agent that generated the data (or more precisely, the software engineer that produced the software agent) possesses the know-how to "decode" the data, i.e., to connect the signifier with what is signified in reality. The realm of that know-how, denoted here as *background knowledge*, represents the semantic monolith, and it is being demarcated in design time: any software agent that, through its software engineer, is made aware of that background knowledge, through bilateral agreements, domain-specific standards or other conventions, has implemented measures to apply the data in accordance to what they refer to in reality. In conclusion, sIOP cannot exist without sharing the background knowledge that relates the used signifiers (tokens) with what is signified in reality.  And here we hit the concrete wall of infinite regress, depicted in Figure 2, since communicating background knowledge is equivalent to communicating data: we communicate bare tokens, the decoding of which requires background knowledge itself. It is this infinite regress that makes it impossible to communicate the relation between the signifers (tokens) and the signifed in reality. Ipso facto, where semantics cannot be communicated, semantic interoperability cannot emerge, hence the semantic gap.   
Where and when to position her is a question of architecture: to balance, e.g., the complementing capabilities and shortcomings of man and machine, and particularly to complement the shortcomings of weak AI with human's strong AI; or functionality that should coagulate into software code versus required adaptivity by human-assisted configurations, or maximizing reuse of weak AI artifacts and minimizing deployment delays, to name a few.    
focus on the next best that we *can* influence, being the *ontological commitment*. What we mean with this is the following: When we use a term, and particularly a term from the highest level of abstraction of our (modelling) language, to what *category* of things (or relations) in reality do we refer, i.e., what things in reality do we commit to when using those abstract terms from which all other elements in our model originate. Indeed, to achieve sIOP we side step the grounding problem and apply the ontological commitment in a function of *semantic convention*. This suggests that ontological commitment is absent in contemporary software models. A characteristic of ontological commitment, however, is that its absence is impossible; on introducing a concept, i.e., an element in a (software) model which stands for a particular category of entities (or relations between them) in reality, there always exists background knowledge on the characteristics of that category. For instance, what individuals are considered part of it and how these individuals relate to other categories, or what other categories are contained within it. Such background knowledge, consciously or not, represents the ontological commitment of that concept when it impacts on how the concept plays along with the other elements in the model and, eventually, how individuals that belong to that concept, i.e., data, are being processed by the software. We do not suggest that ontological commitment is absent, but claim that the *explication* of the ontological commitment is either absent, and/or the number of concepts that carry an ontological commitment is *extremely small* in contemporary modeling languages. In other words, every model assumes an underlying ontological commitment; by keeping this implicit, no matter how thoroughly designed the model has been, its underlying ontological commitment is non-existent for the collaborating peer, which clearly ruins sIOP. Acknowledging its significance to sIOP and the architectural concerns that the ontological commitment addresses, the roles it plays, its position within and contributions to other artifacts in the architectural realm, these are necessary criteria to be included in architecture paradigms that claim to support sIOP. To the best of our knowledge, none of the contemporary architectural paradigms, be it view-based models such as Kruchten, IEEE1471-2000, the Zachman Framework [@Zachman1987], RM-ODP [@Linington1995], TOGAF [TBD], DoDAF [TBD], and RASDS-E [TBD] alike, or model-driven architectures that follow from the OMG [TBD] reference architectures, acknowledge the significance of ontological commitment for sIOP and provide for guidelines on how to go about it.   
This publication presents architectural cornerstones for a highly needed access-and-play sIOP capability. To that end, we discuss the necessity for a human-in-the-loop approach, its contradiction with the access-and-play sIOP capability, and describe how these conflicting sIOP concerns can be architecturally balanced. Furthermore, we discuss the need to acknowledge ontological commitment and provide for suggestions to its integration in view-based and model-driven architectural paradigms.   
&gt;Insert overview of article, where possible combined for each section with shortcomings of related work.  
----------  
Earlier monolithic aspects of software have always been "abstracted away". Abstracting from the application code the particulars of the (extra-)functional asset at hand is done by extracting them into a distinct component that can provision the necessary (extra-)functional services outside the monolith. Then, by assuring that these services can be accessed through a *standardized interface*, any application can make use of its (extra-)functional assets, with which the monolithic characteristic was effectively removed. Regarding sIOP, then, the task would be to abstract the particular data semantics from their original application in order to enable re-use of that data outside their original monolithic application. Such approach assumes that agreement can be reached on the subject at hand, which, for many if not all previous monolithic aspects of (hardware and) software hold indeed: the system engineering community had to agree on *how* the abstraction was to take place, as opposed to *what* was being abstracted. Unfortunately, in case of semantics, the debate is primarily on *what* aspect of reality is being abstracted. This comes very close, or is even identical, to a discussion that continues already since Socrates (around 350 BC); philosophers try to understand the metaphysical and physical universe including humans and their world. Without claiming a philosophical origin *per se*, semantic inconsistencies remain widespread, in semantic standards, vocabularies or other conventions about the meaning that should be given to syntax and structure [@Guarino1994a]. More often than not, these inconsistencies are manifestations of our individual background knowledge, believes, cultural entail, and perspectives that led to certain linguistic use. In short, we take the stance that semantic heterogeneity should *not* be considered a bug to be corrected by insisting on one single truth, but a feature that should be exploited to express ourselves as accurately as possible. This sharply contrasts with our departure that we only consider “weak AI”, which assumes that the capability of software towards “understanding” is limited to comparing syntax and following logical rules, only. This contradiction is the first question that we investigate, and to its resolution we present in Section 2 background material on what signifies semantics and the role of semiotics, and set the baseline for this paper by providing for our interpretation on semantics *in* and semantic interoperablity *between* software agents.  
Literature clarifies that "weak AI" is not capable to resolve semantic heterogeneity at run time, while its counterpart "strong AI" does not yet exist and is expected to emerge in long term only, if ever [@XiuquanLi2017]. Therefore, if we want to bridge the semantic gap at run time, we must prepare such capability at design time and introduce a human in the loop to reconcile the different world views of collaborating software agents. However, design time reconciliation is contrasting with the *access-and-play* capability that we imply when we speak about sIOP.     
This contradiction is the second issue that we address, and in Chapter 3 we take a principled approach and investigate the primary concerns that are pursued with an architecture for sIOP and the principles for its underpinning. This gives the necessary foundation for analyzing the optimal balance between design time capabilities for reconciliation and maximizing the run time progress towards the access-and-play demands.  
the services that result, the standards that such services would require and the available initiatives that represent potential candidate standards. An architecture for sIOP should be designed to consolidate related architectural concerns about data re-use and independent application development for collaborating software agents, bringing secondary benefits on concerns about semantic maintainability and modifiability. .   
an explicit check and balances between     
In this paper we discuss the architectural implications for a definitive sIOP capability in support of such access-and-play potential for software agents, which at some point in their life cycle will be faced with the need to exchange data with other (however unanticipated) software agents. A major concern for semantic interoperability is then to balance between at least three conflicting demands. Firstly, to be able to express oneself as accurately as necessary (but not more), i.e., to adopt a language that is sufficiently adequate to represent the notions that we are interested in but neither less nor more. Secondly, to become independent, to the greatest extent possible, from the syntax that is used to represent semantics, i.e., to remain free from representational conventions. Thirdly, to exchange data between collaborating software agents such that the state of affairs the data refer to, remains the same, i.e., "that data elements are understood in the same way by communicating parties" (extract from EIRA).  We elaborate on the consequences of this and similar concerns that we consider the fundamental sIOP concerns in Section 3. We also find (i) that these concerns are not addressed by any of the contemporary, view-based architectural models, i.e., Kruchten, IEEE1471-2000, the Zachman Framework [@Zachman1987], RM-ODP [@Linington1995], TOGAF [TBD], DoDAF [TBD], and RASDS-E [TBD] alike; (ii) that a similar situation holds for the model-based architectural paradigm (MDA/MDE), albeit in a more subtle way that involves philsophy and refers to the relationship with reality; (iii) that generic interoperability (IOP) is already widely acknowledged as an architectural concern by, e.g., software quality models (ISO SQuaRE [TBD] and ISO-9126 extended [@Zeist1996]), as major quality attributes (and related tactics) by [TBD software engineering institute] and [@Bass2013]; (iv) that in order to reach IOP, semantics are identified as its a cornerstone however propose as tactics to manage the interfaces, only, implying some notion of mutual agreement; and (v) that although specific IOP frameworks, such as the EIF and EIRA from the EC, indeed identify a semantic viewpoint, most of the solutions are however based on mutual agreement, usually in the form of standards. These findings, together with our stance to embrace semantic heterogeneity, justify the demand for an explicit and more formal approach towards semantics and sIOP in contemporary architectural paradigms.   
We observe that concerns result in basic architectural pattern, and therefore apply concerns on sIOP as main foundation to our work. To that end, we gather in Section 4 these concerns and investigate about the architectural principles that are foundational to the provisioning of a sIOP capability in software agents. We conclude that for the large part it is necessary to provide for *loose coupling* at the semantic level, i.e., become, to the greatest extend possible, independent from how semantics have been expressed in syntax by the collaborating peer. In Section 5 we show how these sIOP principles can be consolidated, first as an additional architectural view and viewpoint for view-based architectures, and in a semantic model with semantic components for model-based architectures. Finally, in Section 6 we evaluate our theory on architectural considerations for the consolidation of semantic interoperablity by its implementation in [a desk mockup/ working prototype]. In Section 7 we discuss the results achieved by the work in Section 5, and arrive at the final conclusion that the explicit architectural support for semantic interoperability is a necessary element for the evolution of IT. But first we will present our interpretation on semantics in software, and semantic interoperablity between software components.  
&gt; In addition to the architecture fwk you mention, you might also consider specific IOP frameworks, such as the EIF and EIRA from the EC, which is also architecture centric. IOP is addressed from 4 viewpoints: technical, semantics, organisational and legal. Semantic interoperability is defined as "enables organisations to process information from external sources in a meaningful manner. It ensures that the precise meaning of exchanged information is understood and preserved throughout exchanges between parties. In the context of the EIF, semantic interoperability encompasses the following aspects:  •Semantic interoperability is about the meaning of data elements and the relationship between them. It includes developing vocabulary to describe data exchanges, and ensures that data elements are understood in the same way by communicating parties.  •Syntactic interoperability is about describing the exact format of the information to be exchanged in terms of grammar, format and schemas. " (extract from EIRA) Most of the solutions are however based on mutual agreement, usually in the form of standards.    
&gt; "... perhaps a more productive definition on the Semantic Web is to describe semantic interoperability in terms of shared inferences. "  &gt; The following sections are in a provisional stage only. I will continue on these ...  
[^1] Semiotics: the study of signs and symbols as a significant part of communications. As different from linguistics, however, semiotics also studies non-linguistic sign systems.</Text>
        </Document>
        <Document ID="35">
            <Title>Discussion &amp; future work</Title>
            <Synopsis>Address shortcomings that we discover throughout writing the sections. 

Conclude that by identifying a specific 42010 viewpoint on sIOP, a necessary condition towards the preparation of a sIOP capability in a software agent has been identified which can be applied to all MDE and view-based software architectures.

\end{synopsis}</Synopsis>
        </Document>
        <Document ID="28">
            <Title>Spanning: Alignments</Title>
        </Document>
        <Document ID="50">
            <Title>sIOP concerns</Title>
            <Text>The following concerns relate to the support for semantic interoperability 
1. Allow for independent software development, i.e., sIOP demands  1. a software capability that is open for collaboration, i.e., without a prior established semantic silo.  2. an ad-hoc collaboration, i.e., without additional software development for its achievement, i.e., reverse engineering of the semantic silo. 2. We assume that strong AI, i.e., software that has some form of understanding about reality, will not emerge in the near future, hence, weak AI is all we have (i.e., logic and statistics). Software is therefore 100% dependent on syntax as vehicle for semantics. That inevitably leads to a human in the loop when sIOP is demanded. To get as close to the access-and-play performance of sIOP as possible, the human effort needs to be as small as possible, and out of the actual data communication process.</Text>
        </Document>
        <Document ID="43">
            <Title>The root of the semantic gap</Title>
            <Text>![Infinite regress in semantics: background knowledge is yet another conceptualization (denoted *I*) that requires a token (*R*) to communicate, the interpretation of which requires another conceptualization albeit on a higher conceptual level.](https://i.imgur.com/eFy5pg4.png)  
The corollary of such semiotic stance is of architectural nature: what are its ramifications on the dependencies between software, data, software engineering and business operations? How can contemporary weak AI technologies such as the Semantic Web, ontologies and model driven architectures, contribute to sIOP and what place should they get in the overall software architecture? To what extend can architectural patterns and techniques, such as abstraction and loose coupling, contribute to its realization, and where do they fall short and what is missing, exactly?  
Before we dive into these architectural considerations, we first present the limitations of current approaches towards sIOP. 
* Vocabularies and linked data  * MDA * The top-level model, M3, is defined in itself, i.e., M3-artifacts refer to artifacts from M3 only. This implies that M3 is grounded in model engineering conventions only and neglects any semiotic significance in reality. As a result, each and every artefact that is introduced in any of the other layers, has a dangling semiotic foundation. This implies that every modeling artefact can respond equally well to conflicting characteristics, and hence, cannot provide for any guidance on its interpretation. * Semantic conventions, e.g., standards. Conventions, though, are only possible when their subject has been made explicit.</Text>
        </Document>
        <Document ID="36">
            <Title>References {-}</Title>
            <Text>\setlength{\parindent}{-0.2in}  

\setlength{\leftskip}{0.2in}  

\setlength{\parskip}{8pt} 
Note:
</Text>
            <Comments>brandtp, 9/5/2018 Also show the ref-id per reference *duh*</Comments>
        </Document>
        <Document ID="29">
            <Title>What is semantic interoperabiity</Title>
            <Synopsis>\begin{enumerate}
  \item Explain sIOP:
  \begin{enumerate}
    \item that consequence of data exchange = breaking the atomic semantic monolith = breaking the reciprocity by partitioning the data from its original code, and explain that standards are large semantic monoliths that roofs that point but are as manouverable as an oil tanker, and 
    \item that sIOP demands that despite this partitioning the reciprocity between the code of the receiving agent and the external data shall be re-installed.
    \item Optionally, give a definition on phantom semantics
  \end{enumerate}
  \item We therefore need to extend the semantic coherence Principe into a sIOP coherence principle with a sIOP rational that the result of the semeiosis on receiving agent A’ does not conflict withthe outcome of the semeiosis on agent A: Without maintaining the reciprocity between binary code and the data it operates on, the semeiosis performed by software engineer A’ on the result of the data processing and their subsequent semantics cannot be guaranteed to be similar as intended by the software engineer.
  \item Explain the difference with semantic standards which are basically large semantic monoliths
  \item Introduce Principle: ontological commitment as minimal standard for sIOP, “(...) not in order to know *what there is*, but in order to know what a given remark or doctrine, ours or someone else’s, *says* there is” [@Quine:1953er]
\end{enumerate}

\end{synopsis}</Synopsis>
            <Text>Rephrase: despite the notoriously difficult philosophical questions involved, semantic interoperability can be seen as an engineering problem, namely that of effectively constraining interpretations towards the ones that are considered allowable [@Kuhn2009].

![The various forms of interoperability][def:2semtriangles]


&lt;!-- page additions --&gt;
[def:2semtriangles]: src\images\2SemioticTriangles.png {#fig:2semiotic-triangles width=510px height=216px}</Text>
        </Document>
        <Document ID="51">
            <Title>Principles that prepare for access-and-play sIOP</Title>
            <Text>Therefore, design for  
1. a highly automated semantic reconciliation process with the minimum of human authoring as possible, resulting in a formal alignment between the two ontologies, and  2. a fully automated data mediation that facilitates, during the data communication process, an alignment-based transcription between the two native data languages.</Text>
        </Document>
        <Document ID="37">
            <Title>architectural essentials for access-and-play sIOP</Title>
            <Text>Noodzakelijke elementen:

* ontologies *describe* reality in an open world
    * “not in order to know *what there is*, but in order to know what [...] doctrine, ours or someone else’s, *says* there is”, [@Quine:1953er]
* models *prescribe* the artifacts that together form our system, in a closed world 
* if we are only interested in a one-of sIOP that does not require to adapt to changes, a semantic monolith will do; in a dynamic environment where time-to-engage matters, being prepared to sIOP becomes an essential business asset.


“Semantic heterogeneity is a major problem in realizing interoperability”.
A.P. Sheth. Changing focus on interoperability in information systems: From system, syntax, structure to semantics. In R. Fegeas, M.F. Goodchild, M.J. Egenhofer and C.A. Kottman, editors, Interoperating Geographic Information Systems, pages 5–30. Kluwer, Norwell, MA, USA, 1999.
</Text>
        </Document>
        <Document ID="44">
            <Title>Semiotics, semantics and semantic interoperability</Title>
            <Text>Semantics are often denoted as the understanding of the data. Despite the often used terms *smart* or *intelligent*, e.g., smart watches, or intelligent autonomous systems, computers are inherently stupid. The notion of understanding is completely alien to them. In fact, it is the IT engineer who performs the understanding of data upfront, and implements the proper response to such understanding in program code.   
To get a better grip on the meaning of semantics and semantic interoperability, we address first what signifies semantics before addressing semantic interoperability. For that, we use the tools that are provided by the discipline of semiotics, which denotes the study of signs, reality and meaning.  
In response to earlier distributed demands, the software engineering discipline introduced the component-based development paradigm, subsequently followed by the service-oriented composition paradigm and the contemporary micro-service architectures. Although compositions and (micro-)services replace monolithic applications and enable distributed use, each contemporary software agent still implements a monolith, albeit a semantic one. This can be explained in terms of the semiotic[^1] sign, depicted in Figure 1, as follows. Data, be them numerical values, text strings, identifiers or even pictures and images, are to be considered as *signifiers* only, i.e., tokens *representing* what is signified in the real world.</Text>
        </Document>
        <Document ID="52">
            <Title>Semantics in contemporary architectural paradigms</Title>
        </Document>
        <Document ID="45">
            <Title>Semiotics</Title>
            <Text>Semiotics provides for a model that circumvents the infinite regress that emerges when one tries to explain the meaning of a sign by introducing more signs. For instance, how to represent a value for distance when that can be expressed in metric units or imperial units. Without prior knowledge on that particular decision the value cannot be used appropriately. On trying to convey that prior knowledge by including the unit with the value is futile: again, the unit is deemed to be represented as a token, and again prior knowledge is necessary to decide on its meaning, this time on how particular tokens stand for certain units. As already discerned by de Saussure in 19xx [@Saussure:1983ka], reality and the things therein (the *signified*) are very different from the vocabulary that we make use of to refer to those things in reality (the *signifier*). He used a dyadic model that stressed that together, the signifier and the signified were as inseparable as the two sides of a sheet of paper. The semiotic sign is the whole that results from the signification of the signifier with the signified. This ‘self-containment of the sign’ is one of the major principles of semiotics, and has been depicted in Figure 1: the dotted horizontal line shows this inseparable distinction, the ‘Please Turn Over’ sign that distinguishes the two sides of the same sheet of paper.   
![The dyadic semiotic model. Note that, due to the very nature of the signified, each and every picture that is to represent a semiotic sign, including this one, is by definition a fallacy. Consider this figure to depict the semiotic sign of the purple, invisible unicorn.](https://i.imgur.com/In9Lrhv.png)  
The top part represents the signified, i.e., the reality that we can observe or touch such as the cup of water in front of me, or the water, the cup and their relationship that the cup holds the water. This domain of the signified includes also the non-observable reality such as the mythical world of unicorns, or Middle Earth [@Tolkien:2002eg]; anything that we can think of, be it logical or illogical, following physical laws or provoking them, identifiable by any of our senses or sensors at our disposal, or not identifiable at all, all that is considered part of the domain of the signified. We use the term *entity* to indicate one of the signified. Hence, an entity is part of the domain of the signified only and can be anything: a thing or a group of things, relations between things, aspects of things, events, time; in any world, real, mystic, fantasy, all the same. The bottom part in the figure represents the domain of the signifier. Compared to the domain of the signified, this domain is rather limited since it only contains tokens. Tokens are representations such as scribbles or drawings, sounds of speech or music or the song of a bird, characters, a word, this text, but also pictures and paintings that paint a thousand words, statues and other 3-dimensional objects, and even 4-dimensional objects such as movies. Tokens are part of the domain of the signifier only. We use various terms to indicate a token, or more precisely, a category (or type) that we consider the token to be part of. For example, an often used term is *concepts*, which is the category of tokens that refer to things that be, or events that happen, such as a fly, a queen or her abdication; *instances* belong to the category of tokens that refer to the specific individuals that are considered part of these concepts, such as the fly that is highly irritating me at this very moment; and Queen Beatrix of The Netherlands whom, at the moment of writing, has been abdicated a few years already and is now called Princess Beatrix, indicating that (i) an entity, here the individual woman, can bear more than one token, or (ii) an individual entity can be positioned into multiple worlds (here periods), indicated by distinct tokens. Finally, and most relevant to the distinction between tokens and entities, is the fact that tokens are principally random shapes. Tokens bear no attribute whatsoever that indicates to what entities they refer to.  It is very important to be aware of the dualism of the semiotic sign that, on the one hand, emphasizes the distinction between the signified and the signifier, and on the other hand insists on its self-containment, i.e., the whole or unity of the signifier and the signified. This importance is relevant since it marks that no physical or mathematical relation exists between the reality at the one hand, and the random tokens that we use to refer to that reality at the other hand. Although the signification, represented in Figure 1 by the vertical arrows, implies that the association exists between the two, this signification is only a mental one. Making the association between the signifier and the signified, i.e., constructing the semiotic sign from its distinct parts, is called *semeiosis*. It is considered a bidirectional association, where the direction towards the signified is called *interpretation* and the other way around, towards the signifier, *representation*.</Text>
        </Document>
        <Document ID="38">
            <Title>Work title The Problem</Title>
            <Text>A full automation of sIOP in order to deliver access-and-play interoperability is impossible: in order to use the data from nation A, nation B needs their genuine understanding in advance. The major impediments to such automation is laid in the nature of semantics itself: The meaning of a term ultimately relates to what it denotes in reality, whilst this relation cannot be deferred from the shape, structure or other characteristics of the term itself due to its total arbitrariness. This semiotic explanation on semantics is depicted in Figure ##, and confronts us with the inevitable separation between languages (software code, modelling languages and natural languages alike) and entities in reality (e.g., things, events, properties of things). That terms and real entities are fundamentally different is hardly a new insight when dealing with information systems. However, addressing this fundamental distinction is at best extremely academic [@Steels:2008tr] and without practical solutions at all [@Cregan2007]. To overcome the separation between terms and entities is in artificial intelligence (AI) known as the *grounding problem*. And despite the progress of AI, its capability to gain even a beginning of a genuine understanding, also known as "strong AI", does not yet exist and is expected to emerge on the long term only, if ever [@XiuquanLi2017]. Its counterpart "weak AI" with its otherwise highly relevant and important achievements in reasoning, prediction and analysis, is based on machinery that relies on language only and can therefore never make the step to reality on its own [@Scheider:2012tj]. Negligence of the existence of the grounding problem and its semiotic origins gives rise to two major impediments in information technology, as follows:

* Firstly, we don't understand the characteristics of semantics sufficiently, or in other words, what impact is generated by the grounding problem on the construction of a software agent. If we are asked to point at the semantic parts in a software agent, we can't. While the same question about, e.g., its scalability, will render a lecture about the different principles that are applied and the components that are used to its achievement. Consequently, without clear design principles we are at a loss of how to engineer semantics into software agents, and how to provide for components or artifacts that achieve semantics. 
* Secondly, without knowing how to engineer semantics into software, we are lacking the bridgehead within the software agent that connects with the semantic bridge. In other words, we do not even know how a semantic bridge looks like. Is it an integrated version of the data schemata of both agents? Is it an as small as possible *third* scheme that addresses the shared parts of both schemata only, to be connected to each of the other two reduced schemata? Do we leave both schemata intact, and introduce a connection between them instead? Only when we have come to a conclusion on the semantic bridge, we can address subsequent issues that relate to other architectural concerns, such as scalability? 

OMG languages typically have abstract syntax (the metamodel), concrete syntax (notations and diagrams) and semantics (constraints and behavior). The MOF is closed in that it is defined in itself. Moreover, although its semantics provide for constraints and behaviour of its models, it does so about the structural aspects of its instances only. Hence, it lacks a formal way that can be used to judge the truth-value of its instances. Interpreting the (informal) semantics of the language, that is, assigning a truth value to an instance, can therefore not rely on an unambiguous  in different ways, resulting in possibly inconsistent and diverging implementations.



In comparison, scalability was a big architectural concern in the past, requiring custom solutions. In response to this concern, scalability was standardised in the form of architectural patterns, and finally totally embedded and hidden into the infrastructure. We now stand for a similar, but completely different situation. It is similar, because, while sIOP currently requires custom solutions, the ultimate goal is its disappearance into the infrastructure. It is completely different, because unlike scalability we are not addressing a concern over which we have complete control. For the first time in ICT we are entering the realm of reality for which, even after several thousands of years of philosophical debate, no unified view can be given. Does a lake continue *to be a lake*, even when all its water have been vaporised in summer? How many tragic *events* does 9-11 represent, one, three or thousands? In almost all situations, there is no one single semantic truth: In the case of the German steel producer, both semantics on what `time` denotes are equally valid from one’s own perspective, and equally less valid from the peer’s perspective. Consequently, lacking the ground for a unified semantics, founding solutions to sIOP on semantic standards may be accepted folklore, it remains a fallacy nonetheless. 

====

How to bridge the gap? Three possibilities:

* Monolithic approach: Agree on the semantics of all terms
* Alignment approach: 

====

Still, the most popular solution towards sIOP is to establish a convention on the semantics of the terms that are used during the collaboration. This convention "resolves" the grounding problem in that it represents the know-how to "decode" the data, i.e., to connect the term with what it stands for in reality. Be aware that the realm of that know-how, denoted here as *background knowledge*, represents a semantic monolith, and it is being demarcated by its use in design time only: any software engineer who is made aware of that background knowledge, through bilateral agreements, domain-specific standards or other conventions, can design and implement measures to apply the data in accordance to what they refer to in reality. This solution is not wrong *per se*, and has as bonus that it does away with the consequences of the unresolved grounding problem because each and every term has already been grounded to everybody's satisfaction. In fact, for long-standing and stable collaborations between software agents, which live in business domains that experience only marginal changes in their business, semantic conventions are the most appropriate approach towards sIOP. Nevertheless, when foreign data emerge that are to be used within the semantic monolith, or when the native data are to be used outside the semantic monolith, sIOP, and hence the IT, will fail. sIOP fails because the convention was not shared to these foreign software agents. Moreover, any run-time attempt to communicate the background knowledge that is reflected by the convention is doomed to fail, because knowledge is just data and thus represented by terms that, in this case, are ungrounded. Again, human intervention is required. This time its purpose is not to resolve the grounding problem, but to bridge the semantic gap that originates from differences in groundings between each pair of collaborating software agents. This is called *semantic reconciliation*, and results in an *alignment* between both groundings. Although weak AI can support in that task [@Euzenat:2013ie], due to its inherent limitations it cannot fulfil the task completely without human intervention. In conclusion, to break the semantic monolith and provide a pair of software agents with sIOP, human intervention is required to produce an alignment between the semantic groundings of each software agent. The issues in this matter relate to (i) the inherent conflict between having a human in the loop and an access-and-play demand; (ii) ***analyse the paragraph below and formulate its issues concretely here*** .</Text>
        </Document>
        <Document ID="60">
            <Title>Commonalities and differences between models and ontologies:</Title>
            <Synopsis>Purpose of this section: present a list of differences
Refer , [@Henderson-Sellers2012]

Conclusion as in [@Aßmann2006]: "Specification models focus on the specification, control, and generation of systems; ontologies focus on description and conceptualization (conceptual modelling) of things. Both kinds of models have in common the qualities of abstraction and causal connection."

\end{synopsis}</Synopsis>
            <Text>In order to fully appreciate the results of our work, it is necessary to acknowledge the commonalities and notably the differences between ontology and models. This is especially relevant since in contemporary architectural paradigms models are being used as first class citizens to the architectures, MDA and ISP RM/ODP alike. </Text>
        </Document>
        <Document ID="53">
            <Title>Model-based architectures</Title>
            <Text>This paradigm claims that a separate semantic concern is redundant, since the semantics of each of the models can already be found in their meta-model. Although this is a valid observation for all lower-layered models, it remains abundantly clear that such a meta-model is characteristically unavailable for the top-level model for otherwise it wouldn't be the top-level model. One could argue that the required grounding for the top-level model can be found in descriptive documents, e.g., requirements or vocabularies. Nevertheless, we consider this a poor-men's substitute when it comes to the genuine consolidation of the sIOP concerns.   
&gt; EG: When you say "We propose to replace the models from the OMG-MOF with ontologies, for the latter are more accurate when it comes to semantics.", do you mean here: conceptually using ontologies rather than models ? Are you also referring to the technical stack associated with ontologies ? There are technologies in the MDE space that probably could also make the job (DSL, model transformation), especially when combined with graph technology.  &gt; PB: Valid argument, needs to be included. Response: Any MDA approach to sIOP requires that collaborative software agents share a model. This is contradicting concern 3.1. Without such shared model, no transformation can achieve sIOP. Hence, the semantic silo remains. Naturally, if the implications of a semantic silo are acceptable, the MDA approach may show very effective.</Text>
        </Document>
        <Document ID="46">
            <Title>Semantic interoperability</Title>
            <Text>&gt; Indeed, to achieve sIOP both collaborating partners must share something that extends beyond the domain of application. The higher this shared abstraction, the more generic the sIOP capability.   
- [INSERT notion on communication between two actors about a shared reality]  - [INSERT notion that each application is about its own domain] - [INSERT notion that sIOP is only possible when the domains of application of both software components have some overlap; they do not need to have identical domains of application, nor do they need to have identical levels of aggregation etc.] - [INSERT notion that the business concern on sIOP is about its ad-hoc capability, e.g., process anything published by anybody anytime and anywhere. Implies that only the reality is shared, and not its conceptualization nor its representation] - Semantic interoperability, then, denotes the capability of software to process external data in such a particular way that its semantics is in accordance with the state of affairs about its domain of application. - [INSERT the notion that sIOP is in essence independent on the way that it is realized. However, the usefulness of establishing sIOP *is* related to extra-functionals with which it can be established, ideally as access-and-play capability.]  
DEFINITION: Semantic interoperability : The capability of software to process external data in such a particular way that its semantics is in accordance with the state of affairs about its domain of application.  
&gt; refer also to EIF/EIRA definition ?</Text>
        </Document>
    </Documents>
</SearchIndexes>