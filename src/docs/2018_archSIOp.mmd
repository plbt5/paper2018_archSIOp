---
title:  'Consolidating semantic interoperability in contemporary architectural paradigms'  
subtitle:   
author:  
- name: Paul Brandt  
  affiliation: Eindhoven University of Technology; Netherlands Organization of Applied Scientific Research TNO, Den Haag, The Netherlands   
- name: Eric Grandry  
  affiliation: Luxembourg Institute of Science and Technology, Esch-sur-Alzette, Luxembourg  
- name: Twan Basten  
  affiliation: Eindhoven University of Technology, Eindhoven, The Netherlands  
category:   
bibliography: src/bib/CitedByMe-2018_archSIOp.bib  
csl: templates/environmental-health-perspectives.csl  
abstract: |   
  
  *Context:* Access-and-Play semantic interoperability (sIOP) is the next glass ceiling in IT-based business collaboration. Current approaches towards sIOP rely on conventions on the semantics of the exchanged terms, which can be considered accepted folklore. Approaches to break through the ceiling require some level of automation, and artificial intelligence (AI) can make a difference.       
    
  *Objective:* The objective of this study is to identify and define AI-based fundamental guidance towards access-and-play sIOP in contemporary architectural paradigms.  
  
  *Method:* Our approach is based on the discipline of semiotics. We identify semiotic shortcomings in architectures, establish a semiotic explanation on software semantics and, subsequently, on sIOP. Based on these considerations, we develop guiding architectural principles in support of software semantics and sIOP. We evaluate these principles by designing and formulating an ISO-42010 Architecture Viewpoint and View on sIOP.   
  
  *Results:* The semiotic approach demonstrates semantics in software to be the result of a reciprocity between data and the software code that operates on them. Data exchange breaks that reciprocity and the main concern of sIOP is to re-establish a valid reciprocity. Loosely coupled semantics, semantic alignments and an ontological commitment of the modelling language can be considered the cornerstone to achieve sIOP. The supporting principles are (i) semantic transparency, (ii) semantic separation of concerns, and (iii) explicit computational semantics. The resulting ISO-42010 Architecture Viewpoint and View on sIOP, including a semantic mediation capability, can be considered a pattern to consolidate sIOP in contemporary architectural paradigms.  
  
  *Conclusions:* The major shortcomings in architectural paradigms to account for sIOP are their negligence of semiotic fundamentals and the absence of an explicit ontological commitment that stands at the root of semantics. By their explicit inclusion, access-and-play sIOP can be consolidated in contemporary architectural paradigms.   
  
...

# Introduction #

* *Created:*	Wednesday, December 28, 2016 1:23:05 PM
* *Modified:*	Monday, September 17, 2018 2:56:57 PM
Status:	No Status
* *Phase:*	Revised draft

Never before, data were so ubiquitous, and managed access to external data was so easy. Because current ICT is unable to *use* all that same external, non-native data as access-and-play service, agility in business collaboration is hampered in all domains. For instance, consider the following (allegedly real) example of an interoperability failure.\todo{ brandtp, 9/5/2018 We can apply another example, I’m open to that. Indeed a TOOP example could be appropriate. However, I cannot think of one but maybe Eric can?} 

> A German steel producer upgraded its industrial process robot. Since the majority of the steel production process is dependent on time, from a security point of view the decision was made to not rely on their own internal clocks but to use the German *Braunschweig Funkuhr* time radio signal as source for the exact time instead. At the end of April 1993, when Germany went on summer time, the computer clock of the steel producer went from 1:59 AM to 3:00 AM in one minute. This resulted in a production line allowing molten ingots to cool for one hour less than normal. When the process controller thought the cooling time had expired, his actions splattered still-molten steel, damaging part of the facility.[^fn1]

In this simple example a tiny difference in the meaning of `time` between the steel producer and the national time provider hampered interoperability to the extend of damaging the steel facility. This tiny difference rooted in the assumption by the steel producer that `time` expressed a continuous scale whilst for the Braunschweig Funkuhr, `time` denoted instant clock time for that time zone and therefore represented a non-continuous scale. In order to achieve that both collaborators, here the Braunschweig Funkuhr and the steel producer, can actually *use* their peers data, the need exists to design and implement wrappers that remove any inconsistency between the variations that may occur in terms, structures, dimensions and what have you. Many such variations exist, leading to a range of failures in so-called *semantic interoperability* (sIOP) and Section/Appendix ##\todo{ brandtp, 9/5/2018 Add sIOP-faults as appendix.}  provides for a short overview of sIOP-faults. Unfortunately, it is fundamentally impossible to automate the production of wrappers, because we need a genuine *understanding* upfront, which computers still cannot do.

The most disconcerting consequences of a lack of (automated) sIOP are time-to-deliver, flat interoperability failures, and even seemingly correct but quite invalid data analysis probably leading to faulty system behaviour. Current sIOP implementations are essentially based on the (time-consuming) process of establishing a (local) convention on the semantics of the terms that are exchanged during collaboration, requiring custom solutions and collaboration-dependent software adaptations. Such conventions can be considered a semantic monolith, which makes dealing with data outside the monolith impossible, unless again a time consuming (months) semantic adoption process is applied. Moreover, these semantic conventions consider semantic heterogeneity as a bug instead of a feature necessary to achieve semantic accuracy. But still, this conventions-based approach towards sIOP is accepted folklore in ICT. In view of the large uptake of the Internet, the Internet of Things (IoT), cloud computing and big data, and in view of economical pressure to intensify enterprise collaboration, we consider this approach "too little, too late". Some form of automation is required to resolve these issues, and we place artificial intelligence (AI) at its core. With the separation [coined by @Searle:1980hw] between *strong* AI (a system that can *think* and has a *mind*, in the philosophical definition of the term) or *weak* AI (a system that can only *act* like it thinks and has a mind), we take the position that --unfortunately-- strong AI is not yet available, if ever [@XiuquanLi2017]. We therefore make do with weak AI and show that despite its limitations it still has got a fundamental role to fulfil as carrier for semantics and sIOP, both facilitating the required automation. Weak AI, despite its current applications in Semantic Web or ontologies, has not yet been embedded in contemporary software architectural paradigms.  

In comparison, scalability was a big architectural concern in the past, requiring custom solutions as well. In response to this concern, scalability was standardised in the form of architectural patterns, and finally totally embedded and hidden into the infrastructure. Similarly, sIOP can be considered the architectural concern of this decade. We first need to provide a standardised solution pattern to address semantic concerns before we can embed it in a technological infrastructure. Only then we can claim that sIOP becomes transparent to the developer and that the semantic monolith is taken down. Where scalability resulted in a huge increase in performance-demanding applications against a fraction of the original costs and effort, business agility will emerge once the semantic monolith is removed and semantic services exist at the infrastructural level. Then sIOP becomes an access-and-play operation that can be achieved with data not anticipated for during software design in due time, at any point in their life cycle. Metaphorically speaking, we consider sIOP as a *bridge* overarching a (semantic) gap: with *bridgeheads* (semantic concerns) on each side of the gap, with a *spanning* (semantic aligments) resting on them to structurally support the bridge and its traffic, and with a *roadway* (data mediation) enabling the crossing of the traffic. Finally, architectural *principles* provide the necessary guidance to the architect for the various design decisions that effectively result in a particular bridge over a particular (semantic) gap. Our contributions to consolidating semantic interoperability in software architectures are fivefold, and represented as architectural principles and concerns, as follows:

* *Semantic concerns (bridgehead)*: Abstracting semantics from a tacit software implication into a tangible, computational and distinct artifact provides us with the potential to connect to it and to make comparisons with the semantic artifact of the peer software agent. Based on the discipline of semiotics, we explain why semantics are irrelevant to software. Instead, we should focus on the reciprocity between data and the data processing code of software. This explains, too, the shortcomings of the current approach towards software semantics that rely on prescriptive information models. We argument that the application of ontologies and ontological commitment are fundamental to remedy current semantic shortcomings (\cref{bridgehead-semantics});
* *Weak AI concerns (spanning)*: Since “strong AI” does not yet exist, sIOP remains in demand of human intervention in order to reconcile the semantic differences between collaborating software agents. However, human intervention is time consuming. We reduce the necessary human intervention to complement weak AI to a task that suffices to achieve sIOP, viz. authoring semantic alignments only (\cref{spanning-alignments});
* *Mediation concerns (roadway)*: We provide for a prototypical implementation of a mediator as the necessary component to automatically translate data when transferred between the collaborating software agents (\cref{roadway-mediation});
* *Principles*: We base sIOP on establishing loose-coupling at the semantic level by introducing principles on semantic separation of concerns and semantic transparency (\cref{siop-principles}), and show how these principles can be operationalised;
* *ISO42010 Architecture Viewpoint*: We verify the applicability of the above concerns and principles by formulating their architectural consequences as a specific ISO42010* *sIOP Viewpoint, and we show their proper position in the total architecture as corresponding sIOP view. As ISO42010 is considered a set of best practises for architecture description, and therefore is used with architecture frameworks such as MoDAF, TOGAF, DoDAF, RM-ODP and so on, we conclude that our sIOP Viewpoint and View can be considered to consolidate sIOP for contemporary architectural paradigms (\cref{iso42010-viewpoint-on-siop}).

Based on these contributions we defend that access-and-play sIOP can be embedded and hidden in infrastructural services when considering semiotic fundamentals and adding loosely coupled formal semantics to contemporary architectural paradigms. To that end, we first describe the semiotic fundamentals in \cref{the-semiotic-and-philosophical-foundations-of-semantics}.


# The semiotic and philosophical foundations of semantics #

* *Created:*	Friday, May 25, 2018 3:01:46 PM
* *Modified:*	Friday, September 7, 2018 2:39:27 PM
Status:	No Status
* *Phase:*	No Label

\begin{synopsis}
Purpose of this section: To establish an informal but concrete notion on (i) the semiotic triangle and the relationsbetween its nodes, and (ii) ontological commitment and its relation to modelling languages.

\end{synopsis}


## Semiotics ##

* *Created:*	Wednesday, July 4, 2018 8:30:48 PM
* *Modified:*	Friday, September 7, 2018 2:39:27 PM
Status:	No Status
* *Phase:*	Revised draft

\begin{synopsis}
Present concrete notion on (i) the semiotic triangle and (ii) the relationsbetween its nodes.
Show abstraction/generalisation as stacking of triangles vertically, and representational metalevels as stacking them horizontally.

\end{synopsis}



The discipline of semiotics is the study of signs, reality and meaning. The meaning of a *token* (text, graphics, sound) ultimately relates to what it denotes in reality (the *entity*), whilst this relation cannot be deferred from the shape, structure or other characteristics of the token itself due to its total arbitrariness. In the early 1900s, De Saussure used a dyadic model that stressed that the token and the entity in reality were as inseparable as the two sides of a piece of paper [@Saussure:1983ka]. This piece of paper he called the ***semiotic sign***, denoting the whole. This ‘self-containment of the sign’ remains one of the major principles of semiotics. Constructing the semiotic sign from its distinct parts is called ***semeiosis***. The token, in combination with their ability for semeiosis, provides humans with the tool to converse with each other. The tokens provide humans with a vocabulary, the semeiosis makes them understand about what entities they talk about. Semantics, then, emerges as a result of the semeiosis that connects the distinct parts of the inseparable semiotic sign. 

Sanders Peirce [in: @Sowa:2000di] developed another model to further investigate the semeiosis part of semantics. He built a triadic model of the semiotic sign, including a representamen (the token) and object (the entity), and introduced the *interpretant* which expresses the mental and, hence, individual sense making. This triadic model of the semiotic sign was coined by Peirce as the *semiotic triangle* (ibid.), depicted in \cref{fig:semiotic-triangles}(a), and subsequently used and modified by Ullmann [@Ullmann:1979sL], Ogden and Richards [@Ogden1989], and many others, also in recent years [@Kuhn2009]. We introduce our modifications, as depicted in \cref{fig:semiotic-triangles}(b), which mainly focus on naming conventions in IT architectures, as follows. 

![The triadic model of the semiotic sign, according to Peirce (a), and modified by us (b). Example (c) shows the concept of a cat named “Yojo”][def:semtriangles]

Where Peirce denotes the *object*, we prefer the use of *entity* due to the ambiguous nature of the former in IT modelling and architectures. We consider an entity to stand for a thing or an event, but also a category of entities, a relation between entities and a property of an entity. We will refer to the *interpretant* component as the *conceptualisation*, to underline the individual conceptualisation that is being formed during requirements analysis and conceptual modeling. And we prefer the use of *token* over *representamen*, and consider it both an atomic element as a particular composition of atomic elements. We include denotations for the edges that are connected to the conceptualisation vertex, and use names that underline the individual and mental nature of the sense making. Note that these names are directional, and must be read as the transformations that takes place in that direction. Finally, we add the causal characteristics that the edges represent, introduced by [@Ogden1989], as *adequacy*, *correctness* and *trueness*. Observe that the connection between the token and the entity is drawn as a dashed line to stress that its existence is indirectly only through the conceptualisation and does not exist in any direct means. Whenever we use “sign” we refer to the semiotic self-contained sign. A well-known example of a sign is depicted in \cref{fig:semiotic-triangles}(c), which shows that when we talk about “Yojo”, our cognition interprets it as our cat. 

![Linking triadic models together.][def:linkedtriangles]

Peirce also recognised that multiple triangles could be linked together in various ways [in: @Sowa:2000di]. By stacking them together, as depicted in \cref{fig:linked-triangles}(a), a conceptualisation is made of “representing an entity”: the original concept of a \mywordbox{cat} named “Yojo”, depicted in \cref{fig:semiotic-triangles}(c), is being conceptualised as the concept of a \mywordbox{cat named “Yojo”} and represented by \mywordbox{cat:Yojo}. In [@Eco1976], Eco uses the term *unlimited semeiosis* to refer to the succession of stacking signs that emerge from that, ad infinitum. We consider unlimited semeiosis as addressing a dimension of comprehension about abstraction and generalisation, with an eventual finish in the ultimate \mywordbox{Thing} concept. Linking the triangles horizontally results in different representational metalevels, depicted in \cref{fig:linked-triangles}(b): From right to left, the characters “Y” “o” “j” and “o” are conceptualised as a single \mywordbox{word} and represented as “Yojo”, which is conceptualised as a \mywordbox{name} and represented as “name:Yojo”, which is conceptualised as an \mywordbox{identifier} that might be represented as “Id=’name:Yojo’ ”.    

<!-- page additions -->
[def:semtriangles]: src\images\SemioticTriangles.png {#fig:semiotic-triangles width=600px height=200px}
[def:linkedtriangles]: src\images\LinkedTriangles.png {#fig:linked-triangles width=600px height=230px}
## Ontological commitment ##

* *Created:*	Wednesday, July 4, 2018 8:31:55 PM
* *Modified:*	Tuesday, September 18, 2018 11:52:39 AM
Status:	No Status
* *Phase:*	Revised draft

\begin{synopsis}
Purpose of this section is to show the relevance of a (modelling) language: a language is used to convey distinctions. The distinctions that are aticulated by a language are denoted as its ontologcal commitment. Modelling languages need to show distinctions that are of relevance to the purpose of modelling. The predominant purpose of modelling is to describe (a particular domain in) reality by distinguishing the entities of interest. The ontological commitment for a modelling language therefore should be of ontological nature, “(...) not in order to know *what there is*, but in order to know what a given remark or doctrine, ours or someone else’s, *says* there is” [@Quine:1953er]. The ontological square or its extension into the ontological sextet [describe it] can be considered the most basic one, which have been specialized into several flavours, all called upper-level, or top-level, or foundational, ontologies, e.g., UFO, BFO, DOLCE and more. 

Show how MDE/MDA applies an ontological commitment as defined in M3, which facilitates an equivalent distinction as the ontological square, but less than the ontol.sextet.
 
Optionally, provide for the distinctions/theories that are foundational to the two most appropriate ontological commitments / foundational ontologies: BFO and UFO.
\end{synopsis}


Apart from this strict semiotics notion, semantics are also influenced by philosophy and need consensus on the question “when are we committed to the existence of certain entities?”. It is relevant to acknowledge that humans maintain assumptions and background knowledge, both of which impact their semeiosis and, hence, semantics. This is where the conceptualisation plays an important role as frame of reference to our understanding, also denoted as the *ontological commitment*. 

When the domain analyst asks questions in order to determine the entities that play a role for a particular (domain of) application, the resulting model (of the conceptualisation) represents the commitment that the domain users have about the entities that they consider relevant to discern. We denote this the *domain commitment* from the users to their domain. In philosophy [@Bricker2016], similar questions are asked that relate to “life, the universe and everything” as opposed to a single domain of application: What *kind* of entities exist? Are the universal aspects that seem to be shared between individual entities, e.g., colour of weight, taken to be *sui generis*? These are questions of ontology. However, in a somewhat more pragmatic view these questions can be asked in a more constrained, methodological nature: What kinds of entity exist *according to a given theory or discourse*? This is a matter of *meta-ontology* and its answers provide for a generic framework of distinction that represents a useful meta-model to the domain analyst, denoted the *ontological commitment. *A language is used to convey distinctions, distinctions that are articulated by its ontological commitment.  

Modelling languages need to show distinctions that are of relevance to the purpose of modelling. The predominant purpose of modelling is to describe (a particular domain in) reality by distinguishing the entities of interest. The ontological commitment for a modelling language therefore should be of ontological nature, “(...) not in order to know *what there is*, but in order to know what a given remark or doctrine, ours or someone else’s, *says* there is” [@Quine:1953er]. The ontological square [@Lowe2006b] can be considered the most basic one, which is obtained by considering two formal but independent distinctions: that between *types* (or *Universals*) and *individuals* (or *Particulars*), and that between *characteristics* (or *Properties*) and their *bearers* (or *Substrates*). The resulting four categories are depicted in \cref{fig:onto-square-and-sextet}(a) with causal relations that exist between them. Its extension into the ontological sextet [@Smith2005] is just to acknowledge that at some point the influence of time should be incorporated as well. This has been depicted in \cref{fig:onto-square-and-sextet}(b). Clearly, similar formal distinctions can be observed in contemporary modelling paradigms at their uppermost meta-level: OMG’s MOF M3 metametamodel distinguishes between the *Association* and the *Class*, while the Resource Description Framework’s language distinguishes primarily between a *subject*, an *object*, and the directed *property* relation between them. All these ontological commitments are very generic, intended to be applicable for all circumstances. Unfortunately, being very generic, the ontological commitments remain very sparse regarding their capability as a language to distinguish; for all examples above, it is impossible to differentiate, for example, between the cup and the coffee that it holds, while intuitively, these are very different from each other. The more extended an ontological commitment becomes, the more it can distinguish as a language between things that we are interested in.  

![The ontological square (a) according to [@Lowe2006b], and its extension (b) producing the ontological sextet according to [@Smith2005].][def:osas]

The ontological sextet has been specialised into several flavours, all called { upper-level | top-level | foundational }^[Please select the term you like best.] ontologies, e.g., UFO [@Guizzardi:2015ky], SUMO, YAMAYATO, BFO, DOLCE and more, and with their similarities and differences between them [@Jansen2008]. Not all of them are intended to provide for a complete foundation (UFO, BFO); several are only facilitating (DOLCE), or the result of (YAMAYATO), research into particular philosophical theories. No matter the reason for their existence, they all assume a certain philosophical viewpoint with the purpose to accurately describe categories that exist in reality according to their viewpoint. 

We consider this the philosophical cornerstone for semantics: we can assess the semantic validity of any proposition if and only if the underlying ontological commitment can be referred to. Furthermore, any assessment towards semantic interoperability of two semantic theories cannot be made without an assessment of the similarity between their underlying ontological commitments. Note, however, that “We look to (…) Ontology not in order to know *what there is*, but in order to know what a given remark or doctrine, ours or someone else’s, *says* there is” [@Quine:1953er]. It then remains the responsibility of the (domain) analyst or ontology engineer to select the viewpoint that is most appropriate for its purpose, in order to select the modelling language that describes the types of things that exist in the domain of application the most accurate.


<!-- page additions -->
[def:osas]: src\images\OntoSquareAndSextet.png {#fig:onto-square-and-sextet width=500px height=250px}


# Bridgehead: Semantics #

* *Created:*	Friday, May 25, 2018 2:59:48 PM
* *Modified:*	Friday, September 7, 2018 2:39:27 PM
Status:	No Status
* *Phase:*	No Label

\begin{synopsis}
Purpose of this section: 
\begin{enumerate}
\item From a semiotic perspective, explain what we mean with semantics in software agents, i.e., the reciprocity between data and data processing code (both represented as Term from the semiotic Sign).
\item Establish that for representing semantics, descriptive models (i.e., ontologies) trump prescriptive models (all 42010 models).
\item Conclude that ontologies need their place as single point of reference (trueness) in architectures, and identify their relationship with the rest of the architectures, i.e., all other prescriptive models. Note the issue on Open World Assumption (ontologies) and CWA (prescriptive models).
\end{enumerate}

\end{synopsis}





## What is software semantics ##

* *Created:*	Wednesday, July 4, 2018 8:31:19 PM
* *Modified:*	Wednesday, September 19, 2018 10:36:08 AM
Status:	No Status
* *Phase:*	Revised draft

\begin{synopsis}
The purpose of this section is to explain software semantics as the "reciprocity between data and software code", and show that to some extent, set theory can replace the conceptualisation node.
Conclude that the reciprocity between data and data processing code represents the smallest (atomic) semantic monolith.

Additionally, optionally, show:
\begin{enumerate}
\item the relationship with Grice's distinction in semantics as "what is said" and "pragmatic meaning": DONE
\item OO as initial implementation to consolidate this reciprocity, and the class as implementation of the atomic semantic monolith; 
\end{enumerate}

\end{synopsis}


We take the position that weak AI is essentially a token-based machine without the ability to close the gap between token and reality. Also called the Grounding Problem [@Harnad1990], addressing this fundamental issue in software engineering about semantics is at best extremely narrow [@Steels:2008tr], or not present at all [@Cregan2007]. This implies that the semiotic triangle is denied its conceptualisation vertex, and the sign remains incomplete. This is confirmed by the software engineering discipline herself implicitly, since it consistently speaks of ‘models that represent reality’ in a certain purposeful context *without* factoring the conceptualisation into the equation [@Aßmann2006]. Consequently, the edges that connect the conceptualisation remain vague or necessarily conflate on the relationship between the model and reality, depicted in \cref{fig:software-models-reality}. In terms of [@Quine:1953er] above, we have beheaded the sign and cut-off our “knowledge about our given remark or doctrine”, we deleted that what “we *say* there is”. We have removed the “ontological level” [@Guarino1994b], and with that our “terminological competence [that] can be gained by formally expressing the ontological commitment of a knowledge base” (ibid.). However, since we make do with weak AI and therefore with this beheaded sign necessarily, we must conclude that genuine semantics can not ever exist in current software agents.  

![Software engineering applies a beheaded semiotic triangle in which its edges remain vague or conflate in the single relation between model and reality.][def:softmodelsreal]

During the use of a software agent the semeiosis is taken care of by the human-in-the-loop, viz. the end user at the human-machine interface (HMI) whom interprets the tokens that are displayed (subjectivation). During development of a software agent the semeiosis is taken care of by another human-in-the-loop, viz. the software engineer whom implicitly performs the conceptualisation and explicitly represents this conceptualisation into tokens, i.e., *models*. Consequently, all models are representations of the engineers’ conceptualisations. From the many models that software engineering typically generates we focus on a pair of models that constitute the engineers’ semantics: the information or data models\todo{ brandtp, 8/30/2018 Make use of 42010 terminology}  that refer to the *information entities* in reality, paired with the process or business models\todo{ brandtp, 8/30/2018 ... ditto ...}  that represent the *event entities* that operate on the information entities. Data processing is in its bare form nothing more than tokens that follow a specific language grammar. This bare form is a representation of its quintessence, viz. a run-time notion on the proper way to operate on the data. Together, these models comprise the smallest atomic union that can represent meaning, indicated by [@Grice:1991BT] as a twofold: the *semantic* meaning, or “what is said”, and the *pragmatic* meaning, what we like to understand as “how it relates to our intentions”. 

\begin{mmdef}[Atomic semantic monolith]\label{def:atomic-semantic-monolith}
An Atomic Semantic Monolith (ASM) denotes the smallest, highest grained pair of models (a data model and a data processing model) that remains faithful to the entity in reality that it refers to.
\end{mmdef}

At the modelling level, semantics still exist by virtue of the designer. However, when the software agent is subsequently compiled, its binary code originate from the process model of the model pair (operations, algorithms), and the memory allocation for the data originates from the information model of the model pair (size, format, encoding). At this binary level the software engineer has left the building, and with her the conceptualisation vertex and the subsequent capability for semeiosis and, thus, semantics. In other words, at binary level we have lost the capability to verify the semantic coherence between the code and the data while the reciprocity between data and software code determines the semantic validity of the data processing. For instance, consider a data element $t$ to represent temperature, and a data algorithm to establish fever, e.g., `t > 37.0` $\to$ `fever`. The one and only means to keep the software from failing is that both the data and the algorithm (i) are expressed in the same unit of dimension ($\si{\degree}C$ in this example), apply the same (ii) resolution and (iii) accuracy, to name a few obvious constraints. We, therefore, take the stance that semantics can only exist in software by virtue of the semeiosis by the human-in-the-loop, while in the software agent itself semantics are necessarily reduced to the reciprocity between data and software code. Still, the software agent acts as transport medium for the semantics as intended by the software engineer to the semantics as experienced by the end user at the HMI. We therefore consider the coherence between data models and data processing models essential for enforcing the software agent to maintain a semantic valid reciprocity between binary code and the data it operates on. 

This leads to the definition of a (normative [@Greefhorst2011]) design principle to its effect:

\begin{mmdp}[Semantic coherence principle]\label{dp:semantic-coherence-principle}

Establish explicit coherence between the models that are contained in a semantic monolith.

\textbf{Type of information:} business

\textbf{Quality attributes:} (semantic) accuracy, reusability, manageability, understandability 

\textbf{Rationale:}
\begin{enumerate}
\item Semantics in software agents are necessarily reduced to, and emerge from, the reciprocity between the data and the binary code that operates on them;  
\item Without explicitly addressing -- at modelling level -- \textbf{all} facets that influence the coherence between the data on the one hand, and the operations that apply on them on the other, the software agent cannot guarantee to maintain the reciprocity between them at the binary level;
\item Without maintaining the reciprocity between binary code and the data it operates on, the semeiosis performed by the end user on the result of the data processing and their subsequent semantics cannot be guaranteed to be similar as intended by the software engineer.
\end{enumerate}
\textbf{Implications:}
\begin{enumerate}
\item The coherence principle is a necessary condition for supporting semantic interoperability;
\item The scope of semantic validity \& accuracy is addressed explicitly and can be referred to;
\item Reuse of data often implies reuse of the data processing code, and vice versa. Having established explicit coherence improves the quality of data and code reuse, and facilitates the verification that the scope of the semantic validity \& accuracy applies in the new context as well;
\item manageability ...?
\item understandability ...?
\end{enumerate}  
\end{mmdp}
Coherence between models can be established with use of a single unique reference against which the truth of the expressions of both models can be verified. In semiotics, this single unique reference is considered reality, as indicated in \cref{fig:semiotic-triangles}(b) by the *trueness* characteristic. Except as toy example in [@Steels:2008tr], this is clearly not possible. The *correctness* characteristic is the only alternative left, taking the conceptualisation node as its principle point of reference, as depicted in \cref{fig:single-semantic-reference}(b). This is exactly what the mathematical branch of *formal semantics* achieves [@Gamut1991; @Genesereth:1987dg] with its three main characteristics, depicted in \cref{fig:single-semantic-reference}(a), viz. connecting (i) an abstract syntax of a language to (ii) a domain of interpretation (usually a set theoretic framework) by defining (iii) an interpretation function from the abstract syntax onto the set theoretic framework. In terms of the semiotic triangle, \cref{fig:semiotic-triangles}(b), this implies the following:

(i) the *representation* node represents models that can be formulated by use of an abstract syntax (and grammar) as its modelling language. In this reading, a model is a particular constellation of tokens that represent a particular state of affairs;
(ii) a particular *conceptualisation* can be mathematically formulated as a specific constellation of (unnamed) individuals, sets of individuals, and sets of sets; 
(iii) the *subjectivation* edge can be formulated as the interpretation function that assigns a mapping from modelling language tokens onto the set elements, enabling the evaluation of a specific model against the intended conceptualisation from (i). 

In this way, the cognitive quality of the conceptualisation can be substituted with set theory. Formulating the conceptualisation as a set theoretic model essentially remains a representation, albeit a mathematical one. One can argue that such substitution does not resolve the grounding problem, and appropriately so. Still, mathematics provide for a very exact way to express oneself, reducing the ambiguity that comes implicitly with any other language, and such mathematical constructs come as close to the conceptualisation as we possibly can get with a token-based machine. Furthermore, logical constructs used at the syntactical level can be interpreted into set theoretic operations, facilitating the evaluation of (complicated) expressions. Formal semantics thus provides a domain of discourse about a particular conceptualisation as principle point of reference for both the data model and the data processing model. The particular conceptualisation is then replaced with a particular Domain of Interest, and both subjectivation relations are replaced with their interpretation function on the abstract syntax of the models. 

![Maintaining the reciprocity between data and data processing models through a single semantic reference, viz. the conceptualisation (b), represented as Domain of Interest, viz. a selection of individuals with domain specific characteristics defined as sets (a).][def:ssref]

In conclusion, we explain software semantics as the reciprocity between data and software code, realised by maintaining the coherence between pairs of data and data processing models, by applying formal semantics to formulate a particular conceptualisation as a domain of interest that can act as semantic reference, and interpretation functions which perform the subjectivation from the data and operation models to that reference.

<2nd Principle: Make the ASM as small as possible, but not smaller than required to express a semantic element. Too vague, yet. Not necessary to convey the primary message, imo.>


<Elaborate on OO to consolidate the reciprocity; take the class as example of a semantic monolith, the minimal, atomic one.>

<!-- page additions -->
[def:softmodelsreal]: src\images\SoftwareModelsReality.png {#fig:software-models-reality}
[def:ssref]: src\images\SingleSemanticReference.png {#fig:single-semantic-reference}
## Explicit semantics ##

* *Created:*	Wednesday, August 22, 2018 11:19:51 AM
* *Modified:*	Wednesday, September 19, 2018 11:50:38 AM
Status:	No Status
* *Phase:*	Argumentation

\begin{synopsis}
The purpose of this section is to establish that for representing semantics, descriptive models (i.e., ontologies) trump prescriptive models (all 42010 models)

Firstly, describe that formal semantics can to some extend take the role as conceptualisation, and hence using set theory as conceptualisation is the best option we have to address semantics. Consequently, show that semantic ambiguity then "only" follows from 4 construction issues (already presented in text below).

Secondly, make the distinction between descriptive and prescriptive models [@Henderson-Sellers2012], and in [@Aßmann2006]: "Specification models focus on the specification, control, and generation of systems; ontologies focus on description and conceptualization (conceptual modelling) of things. Both kinds of models have in common the qualities of abstraction and causal connection."

Second argument shows that (i) the trueness of a model is laid in reality, which is impossible to achieve, and that (ii) the next best we can achieve is establishing the correctness of a model against its conceptualisation node. Finally, observe that (iii) 4 issues will influence the correctness of the model. Then conclude that the best tool to control these issues are the logics from descriptive models (viz. ontologies) at the one hand, and its use as ontological commitment for the prescriptive models (viz. the 42010 models)

Conclusions:
\begin{enumerate}
\item ontologies are more appropriate artefacts for conceptual models than system models
\item as in [@Aßmann2006]: "Specification models focus on the specification, control, and generation of systems; ontologies focus on description and conceptualization (conceptual modelling) of things. Both kinds of models have in common the qualities of abstraction and causal connection."
\end{enumerate}
\end{synopsis}


Despite being a mathematical representation, the sets and individuals in the DoI remain nameless. It is necessary to represent them in a (pair of) model(s) that is tangible, computational and a distinct artifact in order for the software agent to use it and, eventually, make comparisons with the semantic artifact of the peer software agent. The model that describes semantics best is a model that is as faithful to reality as possible, without ambiguous interpretations. Ambiguities emerge from differences that occur between the conceptualisation and the model when constructing the latter. In literature, four construct issues are considered between a conceptualisations and its representation in a model, depicted in \cref{fig:construct-issues}. An exhaustive treatment can be found in [@Guizzardi:2005vt], see also [@CarvalhoeSilva2012; or @Azevedo2015].

![Four different types of construction issues that come with formal semantics. Which one is more clear: (a)[@CarvalhoeSilva2012] or (b) [@Azevedo2015]?][def:constructissues] 

The more precise the representation of the conceptualisation, the higher its *comprehensibility appropriateness\todo{ *brandtp, 9/19/2018 describe/explain the term} *.* Semantic accuracy improves when minimising the four construct issues:

* *Construct overload*, or *non-lucidity*, emerges when the interpretation function maps an element from the abstract syntax onto more than one element (individual, subset) from the conceptualisation: One token can mean more than one thing, e.g., *bank*;
* *Construct excess*, or *unsoundness*, represents an abstract syntax element that does not map onto an element from the conceptualisation: One token does not have a meaning at all;
* *Construct redundancy*, or *non-laconicity*, occurs when more than one abstract syntax element can be used to represent an element from the conceptualisation: More tokens mean the same, e.g., ...\todo{ brandtp, 9/19/2018 find proper example} ;
* *Construct deficit*, or *incompleteness*, specifies the situation where a conceptual element does not map onto a token: It is impossible to express a concept because the language has no token for it, e.g., <example intentionally left blank>.

The best representation of a conceptualisation, then, is a model that is lucid, sound, laconic and complete, i.e., the interpretation/representation mapping is isomorphic. This is difficult to achieve, and the ontological commitment of the modelling language proves a useful tool.  



This begs the question what we mean with model, and what criteria we should adopt to represent a conceptual model. This is especially relevant since in contemporary architectural paradigms models are being used as first class citizens to the architectures, MDA, IEEE-1471 and ISP RM/ODP alike. 



     
1. Explain: difference between ontologies and models
    i. Models lack an elaborate ontological commitment, domain ontologies naturally evolve on foundational ontologies (that express an ontological commitment)
    ii. For prescriptive models, truth lies in meta-models (good for deterministic behaviour); ontologies are descriptive models for which the truth lies in reality (good for semantics)
    iii. ontologies have open world assumption (semantic under-specification), models have closed world assumption (data remain consistent, good for performance)
    iv. Models specify systems, ontologies conceptualise reality (entities) 
    * Try to also connect the onto/model distinction with above principles 
    * Induced problem: from OWA (domain ontologies) to CWA (information/data models), viz. how to get closure?
    * Principle: use domain and business ontologies for “computational independent”-ish models [@Aßmann2006]
    * Bridge descriptive --> prescriptive models by grounding all prescriptive model elements with concepts from descriptive model (see e.g. \cref{fig:OntosInMDE}).


In the remainder of this text we will refer to the formulation of the reference conceptualisation as a *conceptual model*.

![The use of ontologies in MDA, from [@Aßmann2006]][def:ontoMDA]

<!-- page additions -->
[def:ontoMDA]: src\images\OntosInMDE.png {#fig:OntosInMDE  width=568px height=346px}
[def:constructissues]: src\images\ConstructIssues.png {#fig:construct-issues  width=533px height=210px}

# Spanning: Alignments #

* *Created:*	Friday, May 25, 2018 3:04:29 PM
* *Modified:*	Wednesday, September 5, 2018 12:34:17 PM
Status:	No Status
* *Phase:*	No Label




## What is semantic interoperabiity ##

* *Created:*	Wednesday, July 4, 2018 8:40:57 PM
* *Modified:*	Monday, September 17, 2018 3:35:43 PM
Status:	No Status
* *Phase:*	Argumentation

\begin{synopsis}
\begin{enumerate}
  \item Explain sIOP:
  \begin{enumerate}
    \item that consequence of data exchange = breaking the atomic semantic monolith = breaking the reciprocity by partitioning the data from its original code, and explain that standards are large semantic monoliths that roofs that point but are as manouverable as an oil tanker, and 
    \item that sIOP demands that despite this partitioning the reciprocity between the code of the receiving agent and the external data shall be re-installed.
    \item Optionally, give a definition on phantom semantics
  \end{enumerate}
  \item We therefore need to extend the semantic coherence Principe into a sIOP coherence principle with a sIOP rational that the result of the semeiosis on receiving agent A’ does not conflict withthe outcome of the semeiosis on agent A: Without maintaining the reciprocity between binary code and the data it operates on, the semeiosis performed by software engineer A’ on the result of the data processing and their subsequent semantics cannot be guaranteed to be similar as intended by the software engineer.
  \item Explain the difference with semantic standards which are basically large semantic monoliths
  \item Introduce Principle: ontological commitment as minimal standard for sIOP, “(...) not in order to know *what there is*, but in order to know what a given remark or doctrine, ours or someone else’s, *says* there is” [@Quine:1953er]
\end{enumerate}

\end{synopsis}


Rephrase: despite the notoriously difficult philosophical questions involved, semantic interoperability can be seen as an engineering problem, namely that of effectively constraining interpretations towards the ones that are considered allowable [@Kuhn2009].

![The various forms of interoperability][def:2semtriangles]


<!-- page additions -->
[def:2semtriangles]: src\images\2SemioticTriangles.png {#fig:2semiotic-triangles width=510px height=216px}
## Expicit sIOP by alignments ##

* *Created:*	Tuesday, August 28, 2018 10:29:09 AM
* *Modified:*	Friday, September 7, 2018 2:39:27 PM
Status:	No Status
* *Phase:*	Argumentation

\begin{synopsis}
Thus:

\begin{enumerate}
\item Follow the coherence principle and conclude that the models from which *external* data and *receiving* data processing code are derived, need to be brought into coherence with each other.
\item The coherence principle already enforced a single unique reference for each agent. Re-installing coherence demands a semantic alignment between those single unique references. 
\item The purpose of that alignment is to establish how the truth of expressions that are formulated in terms of agent A, can be estabished by using formulations in terms of agent A' against the single unique reference from A'. 
\item The language that is used for expressing the alignment should be fit for its purpose. Refer to EDOAL [@Scharffe2011] as the currently most complete one.
\end{enumerate}

\end{synopsis}






![The three semantic concerns are related: conceptual modelling, semantic reconciliation, and semantic mediation][def:3Concerns]


<!-- page additions -->
[def:3Concerns]: src\images\3SemanticConcerns.png {#fig:3Concerns width=495px height=693px} 

# Roadway: Mediation #

* *Created:*	Friday, May 25, 2018 3:04:50 PM
* *Modified:*	Friday, September 7, 2018 2:39:27 PM
Status:	No Status
* *Phase:*	Argumentation

\begin{synopsis}
Purpose of this section: Establish requirements for a *generic* mediator.

With mediation we denote the process of transcribing a data term that originates from Agent A into a data term that matches a term familiair to Agent A', based on both agents' ontologies and the alignment between them. The main issue here is that although many different types of relation can be defined between the concepts of ontology A and A', e.g., superset of, a transcription of a token from A into a token from A' is a complete replacement and, hence, implements an equivalence relation. In [@Brandt2018b], we show a semantic valid transcription process. The requirements of a mediator are:

\begin{enumerate}
\item Being a generic service
\item Fully defined by two ontologies and their alignments
\item Allows for semantic valid transcriptions only, where 'validity' refers to absence of inducing phantom semantics.
\item Appropriate behaviour for non-translatable content, which should apply only as result of an incomplete alignment, a logical incorrect alignment, or attempts to communicate content that is considered irrelevant for the receiving agent.
\end{enumerate}
\end{synopsis}
# sIOP Principles #

* *Created:*	Friday, May 25, 2018 2:22:13 PM
* *Modified:*	Friday, September 7, 2018 2:39:27 PM
Status:	No Status
* *Phase:*	Argumentation

\begin{synopsis}
Purpose of this section: 
\begin{itemize}
\item Show the semantic architecture as an additional layer that is orthogonal to current layers, expressing a separation of concerns between syntax and semantics (see [@Brandt:2013jh])
\item Define loosely coupled semantics as a result of applying the 2 principles 'semantic separation of concerns' and 'semantic transparency' (see [@Brandt:2013jh])
\item Repeat the Coherence Principle, the sIOP Coherence Principle, and the Ontological Commitment Principle, and show how they fit in the semantic architecture
\item Better structure informal text below, towards more Principle definitions.
\end{itemize}
\end{synopsis}


The main (business) requirement is to achieve sIOP as quickly as possible, with as minimal effort as possible, for collaborations that had not been foreseen and consequently could not be anticipated for during design time of the (two or more) software agents.

Consequently, the software agents have been developed totally and completely independent from each other. This raises the following semantic concerns:

1. Loosely coupled semantics:
    i. Define semantics once during software design phase, and achieve sIOP many times with many different peers
    i. EW Dijkstra: Connected but as independent as possible. In its original reading this implies only defining the *what* but leaving the *how* transparent. For semantics the implication is a more abstract one: the semantics of what is being communicated shall remain transparent to *how* it is represented. More specifically, agents shall rely on an external oracle that can change the semantic vehicle from its original source native representation to the destined target representation, without changing the semantic cargo. Agents, then, can communicate in their own native representations without the need to learn or integrate their peers’ representations.
1. Scalable sIOP:
    i. Variable in number of peers
    i. Variable in level of semantic heterogeneity
1. Semantic concerns are foundational to sIOP (see \cref{fig:3Concerns} for three related ones):
    i. Explicit and computational semantics by *conceptual modelling*: Bridgehead 
    ii. Managed and controlled sIOP by *semantic reconciliation*: Spanning
    iii. Automated sIOP by *semantic mediation*: Roadway. Address semantic issue about the non-equivalence between an alignment and a transcription (refer to \cite{Brandt2018b})

*Ad. Dijkstra’s “Connected but as independent as possible”*. Complement weak AI with human brain:

 * use AI where possible (computational semantics for software agent; supporting semantic reconciliation)
 * use human brain where necessary (but not more): ontology engineering @ design time; alignment authoring @ pre-runtime

     
***Achieve loosely coupled semantics***
  
Loose coupling is founded on principles about (i) separation of concerns, and (ii) transparency:
   
* Principle *Separation of concerns*:
    * Classical: 
        i. Decompose system in parts
        i. with minimal functional overlap
    * Semantical:
        i. Separate your own semantics (i.e., conceptualisations, viz. let each software agent manage its own abstraction from reality)
        i. from establishing sIOP 
* Principle *Transparency*
    * Classical: 
        i. Agnostic to *how* its functions are being achieved
        1. Communicate with minimal mutual dependency
    * Semantical:
        i. Agnostic to *how* semantics are being achieved
        i. Communicate with minimal syntactic dependency, i.e., without agreements on semantic representation  


Formulate the principles in the format according to [@Greefhorst2011]

*Ad. semantic separation of concern*. Where in its classical application the result of applying the principle is that atomic functions are defined, designed and implemented only once and remain unique, in its semantic application the result of applying this principle is that every software agent maintains its own semantics. Semantics are, therefore, distributed all over the place. This seems counterintuitive or even plain wrong, however, it is necessary for complying with the concern about semantic scalability (in support of heterogeneous semantics). Besides that, it is a direct consequence of the demand to allow for independent software development

 * Principle: specify ontological commitment as basic 
 * Refer to (and partly reuse?) semantic architecture from [@Brandt2013], depicted in \cref{fig:sSoC}

![An architecture for loosely coupled semantics, founded on semantic SoC and semantic transparency [@Brandt2013]][def:sSoC]

 
***Achieve Scalable sIOP***

Ensure that different semantic topologies remain possible:
 
i. Star alignments (central domain ontology, aligned to local ontologies) for relative stable and homogeneous domain semantics
    * Good: easy semantic governance
    * Bad: very big semantic monolith, hence, low agility in dynamic environments
ii. Mesh alignments (bilateral alignments) for very dynamic and heterogeneous (domain) semantics, or low number of peers
    * Good: quickly established bilateral sIOP; granularity-on-demand, viz. intricate where necessary, coarse-grained where possible
    * Bad: complicated semantic governance
iii. Mix-n-Match (coarse-grained star-alignment with specialised bilateral alignments) for the 70% bulk 
    * Good: controllable semantic governance; after central alignment, quickly established bilateral sIOP
    * Bad: slightly more complicated mediation due to double alignment support



<!-- page additions -->
[def:sSoc]: src\images\SemanticSoC.png {#fig:sSoC width=448px height=426px} 


# ISO42010 viewpoint on sIOP  #

* *Created:*	Friday, July 20, 2018 3:43:03 PM
* *Modified:*	Friday, September 7, 2018 2:39:27 PM
Status:	No Status
* *Phase:*	Argumentation

\begin{synopsis}
Consolidate the ideas on the bridgehead, spanning, roadway and principles into an additional ISO42010 Architectural Viewpoint (sIOP) that summarises all previous Sections as concerns on semantics and sIOP. ***Preferrably written by Eric.***

\end{synopsis}
# Related work #

* *Created:*	Sunday, April 22, 2018 5:06:37 PM
* *Modified:*	Friday, September 7, 2018 2:39:27 PM
Status:	No Status
* *Phase:*	Argumentation

\begin{synopsis}
Group the papers into 3 (?) categories, and discuss their strong and weak points in relation to sIOP and architecture in general, and our paper specifically.

\end{synopsis}


Discuss the following papers:

1. M. B. Almeida, C. P. Pessanha, and R. Barcelos, “Information Architecture for Organizations: An Ontological Approach,” in Ontology in Information Science, C. Thomas, Ed. IntechOpen, 2018, pp. 1–27.
2. S. Yang, J. Guo, and R. Wei, “Semantic interoperability with heterogeneous information systems on the internet through automatic tabular document exchange,” Inf. Syst., vol. 69, pp. 195–217, Sep. 2017.
3. U. Aßmann, S. Zschaler, and G. Wagner, “Ontologies, Meta-models, and the Model-Driven Paradigm,” in Ontologies for Software Engineering and Software Technology, C. Calero, F. Ruiz, and M. Piattini, Eds. Springer-Verlag Berlin Heidelberg, 2006, pp. 249–273.
4. C. Atkinson and T. Kühne, “The Essence of Multilevel Metamodeling,” LNCS, vol. 2185, pp. 19–33, 2001.
1. H. Carvalho e Silva, R. de Cassia Cordeiro de Castro, M. J. Negreiros Gomes, and A. Salles Garcia, Well-Founded IT Architecture Ontology: An Approach from a Service Continuity Perspective, vol. 294. Springer-Verlag Berlin Heidelberg, 2012.
1. R. Carraretto, “Separating Ontological and Informational Concerns : A Model-driven Approach for Conceptual Modeling,” Federal University of Espírito Santo, 2012.
1. C. L. B. Azevedo, M. E. Iacob, J. P. A. Almeida, M. J. van Sinderen, L. F. Pires, and G. Guizzardi, “Modeling resources and capabilities in enterprise architecture: A well-founded ontology-based proposal for ArchiMate,” Inf. Syst., vol. 54, pp. 235–262, 2015.
1. M. B. Almeida, C. P. Pessanha, and R. Barcelos, “Information Architecture for Organizations: An Ontological Approach,” in Ontology in Information Science, C. Thomas, Ed. IntechOpen, 2018, pp. 1–27.
1. D. Gasevic, D. Djuric, and V. Devedzic, Eds., Model Driven Architecture and Ontology Development. Springer Berlin Heidelberg New York, 2006. Particularly Part II: The Model Driven Architecture and Ontologies

# Discussion & future work #

* *Created:*	Friday, May 25, 2018 3:05:09 PM
* *Modified:*	Friday, September 7, 2018 2:39:27 PM
Status:	No Status
* *Phase:*	Argumentation

\begin{synopsis}
Address shortcomings that we discover throughout writing the sections. 

Conclude that by identifying a specific 42010 viewpoint on sIOP, a necessary condition towards the preparation of a sIOP capability in a software agent has been identified which can be applied to all MDE and view-based software architectures.

\end{synopsis}
# References {-} 

* *Created:*	Sunday, March 4, 2018 4:08:55 PM
* *Modified:*	Friday, September 7, 2018 2:39:27 PM
Status:	No Status
* *Phase:*	No Label

\setlength{\parindent}{-0.2in}  

\setlength{\leftskip}{0.2in}  

\setlength{\parskip}{8pt} 
Note:\todo{ brandtp, 9/5/2018 Also show the ref-id per reference *duh*} 

[^fn1]: Source: http://catless.ncl.ac.uk/Risks/14.57.html#subj1, accessed May 20, 2018