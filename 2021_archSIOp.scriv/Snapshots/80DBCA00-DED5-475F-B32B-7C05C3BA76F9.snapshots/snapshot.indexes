<?xml version="1.0" encoding="UTF-8"?>
<SnapshotIndexes Version="1.0" BinderUUID="80DBCA00-DED5-475F-B32B-7C05C3BA76F9">
    <Snapshot Date="2018-06-02 16:08:03 +0200">
        <Title>Untitled Snapshot</Title>
        <Text>Purpose of this section: Introduce semiotics and its foundational relevance to semantics, by:

1. Introduce root cause for SIOp issues: grounding problem
1. Introduce semiotic triangle
1. Semantics (for humans) = real thing + referring token + Interpreter
1. Valid semantics (for software agent) = reciprocity between data (referring token) + operations (software code)
1. Introduce ontological commitment

*Grounding Problem*

Books or textbooks on requirements analyses and software design typically warn the designer that “the Term or Concept is very much different from the Thing itself”, and that both should never be confused for each other. That immediately begs the question how we know what Thing is implied when using the Term. We are thus confronted with the inevitable separation between the realm of languages (software code, modelling languages, logical theories and natural languages alike) and that of reality (entities, e.g., things, events and properties of things). The meaning of a term ultimately relates to what it denotes in reality, whilst this relation cannot be deferred from the shape, structure or other characteristics of term itself due to its total arbitrariness. This is known as the *problem of reference*, a manifestation of the *grounding problem* which elucidates that . In information systems, addressing this fundamental distinction is at best extremely narrow [@Steels:2008tr], or not present at all [@Cregan2007]. Despite the progress of artificial intelligence (AI), its capability to build some form of conscience and gain even a beginning of an understanding to relate a term to what it denotes in reality, also known as "strong AI", does not yet exist and is expected to emerge on the long term only, if ever [@XiuquanLi2017]. Its counterpart "weak AI" with its otherwise highly relevant and important achievements in reasoning, prediction and analysis, is based on machinery that relies on language only and can therefore never make the step to reality on its own [@Scheider:2012tj]. Still, it’s all we’ve got at this very moment and we’ll have to make do with it for the time being in order to achieve semantics and SIOp. We therefore cannot neglect the existence of the grounding problem and its semiotic origins. Nevertheless, we do. For instance, when we are asked to explain how we address the grounding problem in the design of our software agent, we can’t; when we are asked to point at the semantics parts in the code of our software agent, we can't. The same question however about, e.g., its scalability, will render a lecture with adequate references to the underlying architecture. We thus remain at a loss of how to engineer semantics into software agents. However, without a clear understanding on semantics and its contribution to the software agent, we are lacking the bridgehead within the software agent that is fundamental to the semantic interoperability bridge. 






In fact, this is a question of philosophy while ICT is “only” faced with its consequence: computers can deal with language only and have no clue about reality. 






It therefore remains impossible to ground the applied terms in reality, denoted as the *grounding problem*. Its resolution is a major subject in strong AI and in (geographic) information science in general \cite{Scheider:2012tj}. Although \cite{Steels:2008tr} provides for an alternative (weak AI) solution, that only shows the need to refer to  general stance is that the grounding problem remains a big challenge .

despite the notoriously difficult philosophical questions involved, semantic interoperability can be seen as an engineering problem, namely
that of effectively constraining interpretations towards the ones that are considered
allowable.



*Ontological commitment*

An appropriate definition for ontology is given by \cite{Guarino:1998wq} as a “logical theory accounting for the intended meaning of a formal vocabulary”. However, apart from how a language theory can be interpreted into its semantic counterpart, semantics are also influenced by philosophy and need consensus on the question “when are we committed to the existence of certain entities?”. </Text>
    </Snapshot>
    <Snapshot Date="2018-06-11 13:15:09 +0200">
        <Title>Pre-Sync External File Version</Title>
        <Text>Purpose of this section: Introduce semiotics and its foundational relevance to semantics, by:

1. Introduce root cause for SIOp issues: grounding problem
1. Introduce semiotic triangle to explain grounding problem
1. Semantics (for humans) = real thing + referring token + Interpreter
1. Valid semantics (for software agent) = interrelation between data (referring token) + operations (software code)
1. Introduce ontological commitment

</Text>
    </Snapshot>
</SnapshotIndexes>