{\rtf1\ansi\ansicpg1252\cocoartf2636
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 CourierNewPSMT;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs24 \cf0 Discuss the following papers:\
\
1. Pagano, P., Candela, L., Castelli, D., & Paolucci, M. (2013). Data Interoperability. In Data Science Journal (Vol. 12, pp. GRDI19\'96GRDI25). https://doi.org/10.2481/dsj.GRDI-004\
1. Fahad, M., Moalla, N., & Bouras, A. (2012). Detection and resolution of semantic inconsistency and redundancy in an automatic ontology merging system. Journal of Intelligent Information Systems, 39(2), 535\'96557. https://doi.org/10.1007/s10844-012-0202-y	\
1. G\'f6tz, S., Beckel, C., Heer, T., & Wehrle, K. (2008). ADAPT: A semantics-oriented protocol architecture. Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 5343 LNCS, 287\'96292. {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1007/978-3-540-92157-8-27"}}{\fldrslt https://doi.org/10.1007/978-3-540-92157-8-27}}\
1. Otto, B., Steinbu\'df, S., Teuscher, A., & Lohmann, S. (2019). Reference Architecture Model (Issue 3). International Data Spaces Association. https://internationaldataspaces.org/wp-content/uploads/IDS-Reference-Architecture-Model-3.0-2019.pdf\
1. (European Commission (DG Informatics) - ISA2 Programme). (2017). New European Interoperability Framework. Publications Office of the European Union. {\field{\*\fldinst{HYPERLINK "https://doi.org/10.2799/78681"}}{\fldrslt https://doi.org/10.2799/78681}}, particularly its related design principles\
\
\
Use as reference in main part:\
\
1. Renner, S. A., Scarano, J. G., & Rosenthal, A. S. (1996). Data interoperability: Standardization or Mediation. 1st IEEE Metadata Conference, 1\'968.\
\pard\pardeftab720\ri-16872\partightenfactor0
\cf0 1. \'93Semantic heterogeneity is a major problem in realizing interoperability\'94, in: A.P. Sheth. Changing focus on interoperability in information systems: From system, syntax, structure to semantics. In R. Fegeas, M.F. Goodchild, M.J. Egenhofer and C.A. Kottman, editors, Interoperating Geographic Information Systems, pages 5\'9630. Kluwer, Norwell, MA, USA, 1999. \
\
\
\pard\pardeftab720\partightenfactor0
\cf0 The authors of \\cite\{Naudet2010\} propose a formalisation of interoperability grounded in the general system theory. \
\
In [@Horsch2020] the authors discuss the ongoing work on establishing a European Virtual Marketplace Framework, into which diverse platforms can be integrated. It addresses common challenges that arise when marketplace-level domain ontologies are combined with a top-level ontology like the European Materials and Modelling Ontology (EMMO) by ontology alignment. A multi-tier system of ontologies is established with the EMMO at the top and all others subsumed by it. The authors show that with such a setup the top-level ontology is crucial in the creation of the alignments between the (domain)ontologies that are subsumed by it. At the one hand this shows support to our conclusion that semantic alignments and an explicit use of ontological commitment can be considered cornerstones to achieve semantic interoperability. At the other hand their particular approach is a centralised one that does not scale well in large distributed environments due to its dependency on one single ontological commitment. Moreover, the top-level ontology, here EMMO, necessarily conflates its function as ontological commitment with a function to construct alignments from. Although this is of great help to resolving the (automated) ontology matching problem, it creates a semantic monolith that extends to all communicating peers which, as we have seen in \\cref\{introduction\}, impedes not only access-and-play sIOP but semantic scalability, evolvability, maintainability and other qualities as well. \
\
The automatic tabular document exchange (DocEx) framework proposed by \\cite\{Yang2017\} divides semantic interoperability into two stages: *interpretation*, described as automatic unambiguous information understanding, and *employment*, understood as the capability to automatically operate on the information according to the interpreted semantics. The interpretation phase is dependent on a global vocabulary that \'93provides uniquely coded and unambiguous concepts across different domains\'94. Essentially, this is a clear example of the *semantic standard fallacy* described by \\cite\{Janowicz:2013ui\}: \'93The successful standardisation of protocols made us believe that we should also standardise meaning on the Web. This is a fundamental misconception\'94, particularly since it defies semantic heterogeneity and different but equally legitimate perspectives on the same thing. The authors remind us of three limitations of the ontology alignment approach; firstly, it cannot guarantee complete semantic interoperability for situations where terms are not aligned; secondly, creating alignments are time consuming; thirdly, ontologies are often local and their point-to-point alignments limits the semantic consistency on a more global scheme. While we do not deny any of these we consider that (i) alignments exist to facilitate interoperability, hence, lacuna are to be (automatically) corrected; (ii) their creation, despite ontology matching algorithms and other automation, will take time but allow for local semantic qualities and independence that are impossible to achieve with a global semantic standard; (iii) local applications are not seeking for global interoperability but business network interoperability only. \
\
The DocEx framework can be considered a simplified version of the openEHR framework^[https://www.openehr.org/, accessed Jan 24, 2020] as introduced by \\cite\{Beale:2001vz\}, further elaborated in [@Beale2007a;@Beale2008a;@Beale2007;@Beale2008;@Beale2007b;@Beale2007c] and incorporated into CEN 13606 as a European and ISO standard. Its founding key paradigm is to model generic knowledge apart from the specific information structures, and let the former constrain the latter: knowledge is expressed as \'93statements which say how instances of a reference model should be constrained to form a valid business entity of some kind\'94. Those statements are embodied by *archetypes*. They introduce a Reference Model (RM) that can be semantically constrained by an Archetype Model (AM). The latter can be considered a meta-model or modelling language to express archetypes, i.e., a particular semantic model representing knowledge. The former is provided to each stakeholder as a unified software implementation (\'94the run-time platform\'94), providing invariant patterns of information structures. This separation makes what the RM is to the AM similar to what the JVM is to the java program. Any information item created by a user is registered as an instance of RM-specified invariant patterns. At the same time that information item is conforming to an archetype that expresses (constrains) its semantics in terms of the AM. Such approach follow \\cref\{dp:rfsm,dp:meoc\} but the application of a central definition of archetypes maintain a tight coupling and thus defies semantic heterogeneity and truly independent semantic representations. \
\
\pard\pardeftab720\ri-17053\partightenfactor0
\cf0 The authors in [@Haller2005] propose the Web Service Execution Environment (WSMX) that enables the execution of Semantic Web Services based on a Web Service Modelling Ontology (WSMO), and consider it a reference implementation for WSMO. It is meant as a means for automated discovery, composition and execution of Web Services which are based on logical inference-mechanisms, and in this way similar to our objective. Another similarity is in their acceptance of semantic heterogeneity and the need for a generic data mediator to overcome semantic differences, thereby following \\cref\{dp:ssoc\}. Despite these similarities, we consider two main differences with our approach. Firstly, the goals of WSMO are of another, broader, dimension than our goal to consolidate semantic interoperability and for which we have introduced details that are out of scope of WSMO. Secondly, \
\
Recently the international data spaces (IDS) association^[https://www.internationaldataspaces.org/the-principles/#overview, accessed Jan 28, 2020] forms the basis for a data marketplace as a strategic link between the creation of data in the internet of things and applying this data in machine learning (ML) and artificial intelligence (AI) algorithms. The proposed architecture is much alike the WSMX in the sense that a well-defined connector provides infrastructural services concerning security and trust, sovereignty, interoperability, ease of adoption and use, and more. In fact, if we conceive WSMX as an abstracted version of Web Services with a particular attention to semantics, IDS can be conceived as an abstracted version of the REST framework that considers data resources (spaces) the central assets in an ecosystem. IDS puts a particular attention to technology transparency when it comes to asset discovery and disclosure, identity, their secure, managed and accountable use, and interoperability. IDS considers data as assets, and provides many if not all necessary components for its managed exchange. Contrarily, we observe a clear absence of any considerations similar to those we bring forward in this paper towards the consolidation of sIOP. Still, and like WSMX\'92s and our objectives, IDS clearly intends to put forward an architectural design with the aim to solve the concerns generically into a transparent infrastructure. In conclusions, we consider IDS\'92 data technology transparency an interesting complement to our data semantic transparency.\
\
\pard\pardeftab720\partightenfactor0
\cf0 [@Greefhorst2011] provides for a Principles Catalogue in their appendix which presents almost sixty design principles. Principle A.20 of them reads *Data that are exchanged adhere to a canonical data model*, and one of its rationals states that *A Canonical Data Model standardizes the definitions of data that are exchanged (...)*. Indeed, principle A.20 reflects the current practises to achieve interoperability. Although it conflicts with \\cref\{dp:ssoc\}, it is not necessarily wrong, since following it results in achieving interoperability as justified by the many if not all interoperable systems that exist today. However, its application impedes access-and-play interoperability as well as semantic heterogeneity, as we have shown in \\cref\{waar-precies\}.\
}