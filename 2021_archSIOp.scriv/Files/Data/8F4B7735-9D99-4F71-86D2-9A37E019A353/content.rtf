{\rtf1\ansi\ansicpg1252\cocoartf2638
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 CourierNewPSMT;\f1\fmodern\fcharset0 CourierNewPS-BoldMT;\f2\fswiss\fcharset0 Helvetica;
\f3\fmodern\fcharset0 CourierNewPS-BoldItalicMT;\f4\fmodern\fcharset0 CourierNewPS-ItalicMT;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs24 \cf0 Discuss the following papers:\
\
1. https://scholar.google.com/citations?user=pkJy5p8AAAAJ&hl=en\
1. Pahl, C. (2007). Semantic model-driven architecting of service-based software systems. Information and Software Technology, 49(8), 838\'96850. {\field{\*\fldinst{HYPERLINK "https://doi.org/10.1016/J.INFSOF.2006.09.007"}}{\fldrslt https://doi.org/10.1016/J.INFSOF.2006.09.007}} \'97> 
\f1\b Compare how they apply onto\'92s for DM
\f0\b0 \
\
1. Maybe discuss as agreement-based approach to sIOP: J.A. Mykk\'e4nen, M.P. Tuomainen, An evaluation and selection framework for interoperability standards, Information and Software Technology, Volume 50, Issue 3, 2008,Pages 176-197, ISSN 0950-5849, https://doi.org/10.1016/j.infsof.2006.12.001. (https://www.sciencedirect.com/science/article/pii/S0950584906001960)\
\
Several works exist that focus on logical foundations of sIOP in search for automatic matching and merging of ontologies [@Euzenat:2013ie;@Benedikt2018a;@Scharffe2014], or for automatic detection and reconciliation of semantic inconsistencies between ontologies [@Fahad2012;@Diggelen:2007vd]. These works lay at the heart of ontology mediation, however, their embedding in the larger software environment is not addressed or only assumed at best. At the same time, several works exist that address the architectural foundations related to information analyses and interoperability, both in academic literature [@Karagiannis2006;@Raghupathi2008] and in industrial practices [@ObjectManagementGroupOMG2013]. Few literature exists on on the combination of foundations for architectural concerns and those for formal semantics, and these make use of ontological foundations to specify the semantics of the capabilities and resources of the architectural language as opposed to domain semantics [@Naudet2010;@Azevedo2015;@Carvalho2016]. \
\
The authors of [@Pagano2013a] present an abstract account of interoperability issues, research challenges and fundamental factors that apply in interoperability. In terms of these findings, our work can be considered on-topic, relevant, and in alignment with their research agenda. It distinguishes from theirs by addressing sIOP solutions to part of their broader and more abstract view on interoperability. \
\
In [@Horsch2020] the authors discuss the ongoing work on establishing a European Virtual Marketplace Framework, into which diverse platforms can be integrated. It addresses common challenges that arise when marketplace-level domain ontologies are combined with a top-level ontology like the European Materials and Modelling Ontology (EMMO) by ontology alignment. A multi-tier system of ontologies is established with the EMMO at the top and all others subsumed by it. The authors show that with such a setup the top-level ontology is crucial in the creation of the alignments between the (domain)ontologies that are subsumed by it. At the one hand this shows support to our conclusion that semantic compatibility can be considered foundational to semantic interoperability. At the other hand their particular approach is a centralised one that does not scale well in large distributed environments due to its dependency on one single ontological commitment. Moreover, the top-level ontology, here EMMO, necessarily conflates its function as ontological commitment with a function to construct alignments from. Although this is of great help to resolving the (automated) ontology matching problem, it creates a semantic monolith that extends to all communicating peers which, as we have seen in \\cref\{introduction\}, impedes not only access-and-play sIOP but semantic scalability, evolvability, maintainability and other qualities as well. \
\
The automatic tabular document exchange (DocEx) framework proposed by \\cite\{Yang2017\} divides semantic interoperability into two stages: *interpretation*, described as automatic unambiguous information understanding, and *employment*, understood as the capability to automatically operate on the information according to the interpreted semantics. The interpretation phase is dependent on a global vocabulary that \'93provides uniquely coded and unambiguous concepts across different domains\'94. Essentially, this is a clear example of the *semantic standard fallacy* described by \\cite\{Janowicz:2013ui\}: \'93The successful standardisation of protocols made us believe that we should also standardise meaning on the Web. This is a fundamental misconception\'94, particularly since it defies semantic heterogeneity and different but equally legitimate perspectives on the same thing. The authors remind us of three limitations of the ontology alignment approach; firstly, it cannot guarantee complete semantic interoperability for situations where terms are not aligned; secondly, creating alignments are time consuming; thirdly, ontologies are often local and their point-to-point alignments limits the semantic consistency on a more global scheme. While we do not deny any of these we consider that (i) alignments exist to facilitate interoperability, hence, lacuna are to be (automatically) corrected; (ii) their creation, despite ontology matching algorithms and other automation, will take time but allow for local semantic qualities and independence that are impossible to achieve with a global semantic standard; (iii) local applications are not seeking for global interoperability but business network interoperability only. \
\
The DocEx framework can be considered a simplified version of the openEHR framework^[https://www.openehr.org/, accessed Jan 24, 2020] as introduced by \\cite\{Beale:2001vz\}, further elaborated in [@Beale2007a;@Beale2008a;@Beale2007;@Beale2008;@Beale2007b;@Beale2007c] and incorporated into CEN 13606 as a European and ISO standard. Its founding key paradigm is to model generic knowledge apart from the specific information structures, and let the former constrain the latter: knowledge is expressed as \'93statements which say how instances of a reference model should be constrained to form a valid business entity of some kind\'94. Those statements are embodied by *archetypes*. They introduce a Reference Model (RM) that can be semantically constrained by an Archetype Model (AM). The latter can be considered a meta-model or modelling language to express archetypes, i.e., a particular semantic model representing knowledge. The former is provided to each stakeholder as a unified software implementation (\'94the run-time platform\'94), providing invariant patterns of information structures. This separation makes what the RM is to the AM similar to what the JVM is to the java program. Any information item created by a user is registered as an instance of RM-specified invariant patterns. At the same time that information item is conforming to an archetype that expresses (constrains) its semantics in terms of the AM. Such approach follow \\cref\{dp:rfsm,dp:meoc\} but the application of a central definition of archetypes maintain a tight coupling and thus defies semantic heterogeneity and truly independent semantic representations. \
\
\pard\pardeftab720\ri-17053\partightenfactor0
\cf0 The authors in [@Haller2005] propose the Web Service Execution Environment (WSMX) that enables the execution of Semantic Web Services based on a Web Service Modelling Ontology (WSMO), and consider it a reference implementation for WSMO. It is meant as a means for automated discovery, composition and execution of Web Services which are based on logical inference-mechanisms, and in this way similar to our objective. Another similarity is in their acceptance of semantic heterogeneity and the need for a generic data mediator to overcome semantic differences, thereby following \\cref\{dp:ssoc\}. Despite these similarities, we consider two main differences with our approach. Firstly, the goals of WSMO are of another, broader, dimension than our goal to consolidate semantic interoperability and for which we have introduced details that are out of scope of WSMO. 
\f2 <$Scr_Cs::0>
\f3\i\b Secondly,
\f2\i0\b0 <!$Scr_Cs::0>
\f0 \
\
Recently the international data spaces (IDS) association^[https://www.internationaldataspaces.org/the-principles/#overview, accessed Jan 28, 2020] forms the basis for a data marketplace as a strategic link between the creation of data in the internet of things and applying this data in machine learning (ML) and artificial intelligence (AI) algorithms. The proposed architecture, [@Otto2019], is much alike the WSMX in the sense that a well-defined connector provides infrastructural services concerning security and trust, sovereignty, interoperability, ease of adoption and use, and more. In fact, if we conceive WSMX as an abstracted version of Web Services with a particular attention to semantics, IDS can be conceived as an abstracted version of the REST framework that considers data resources (spaces) the central assets in an ecosystem. IDS puts a particular attention to technology transparency when it comes to asset discovery and disclosure, identity, their secure, managed and accountable use, and interoperability. IDS considers data as assets, and provides many if not all necessary components for its managed exchange. Contrarily, we observe a clear absence of any considerations similar to those we bring forward in this paper towards the consolidation of sIOP. Still, and like WSMX\'92s and our objectives, IDS clearly intends to put forward an architectural design with the aim to solve the concerns generically into a transparent infrastructure. In conclusions, we consider IDS\'92 data technology transparency an interesting complement to our data semantic transparency.\
\
\pard\pardeftab720\partightenfactor0
\cf0 [@Greefhorst2011] provides for a Principles Catalogue in their appendix which presents almost sixty design principles. Principle A.20 of them reads *Data that are exchanged adhere to a canonical data model*, and one of its rationals states that *A Canonical Data Model standardises the definitions of data that are exchanged (...)*. Indeed, principle A.20 reflects the current practises to achieve interoperability. Although it conflicts with \\cref\{dp:ssoc\}, it is not necessarily wrong, since following it results in achieving interoperability as justified by the many if not all interoperable systems that exist today. However, its application impedes access-and-play interoperability as well as semantic heterogeneity, as we have shown in \\cref\{waar-precies\}.\
\
In support of EU\'92s single digital market, the new European Interoperability Framework (EIF) [@EU-ISA2Program2019] gives guidance to public administrations on how to improve interoperability. It provides three recommendations on the semantic level which are rather abstract in their formulation, although exemplifying these with approaches that can be categorised in FEI [@Chen2017] as 
\f2 <$Scr_Cs::1>
\f4\i integrated
\f2\i0 <!$Scr_Cs::1>
\f0 , or 
\f2 <$Scr_Cs::1>
\f4\i unified
\f2\i0 <!$Scr_Cs::1>
\f0  at best, but not 
\f2 <$Scr_Cs::1>
\f4\i federated
\f2\i0 <!$Scr_Cs::1>
\f0 . These examples imply that our approach is not in compliance with the EIF, which is in contrast with the three recommendations that do not exclude a 
\f2 <$Scr_Cs::1>
\f4\i federated
\f2\i0 <!$Scr_Cs::1>
\f0  approach, or any other of the DPs that we have elaborated.\
\
The authors of [@Neiva2016] present a literature research to pragmatic interoperability. Although no definition on pragmatics or its interoperability is given, the distinction with semantics is given as \'93semantics is related with which the [semiotic] sign refers to, and pragmatics is related to the effect of the sign on the interpreter.\'94. This aligns with our application of semantic meaning and pragmatic meaning. Where the authors keep pragmatics separate from semantics and, therefore, treat pragmatic interoperability separate from semantic interoperability, we consider the reciprocity between them significant and conclude that semantic interoperability can only be achieved when the DSC can re-establish the connection of the DSP\'92s data with its own pragmatic meaning. Opposed to the authors opinion, we consider the pragmatic meaning a necessary element in achieving sIOP. \
\
A quasi-systematic literature review to interoperability in context-aware software systems was undertaken by [@Motta2019], resulting in an Interoperability Theoretical Framework \'93used to guide the evolution of software systems regarding changes focused on interoperability\'94. They identify 16 high-level interoperability mechanisms, i.e., decisions to be taken and solutions recurrently used throughout the software systems to achieve interoperability. Our design principles are in (partial) support of 12(3) of the mechanisms, i.e., \'93Use common ontologies to enable understanding\'94, and \'93Use \'91bridges\'92 to enable interaction\'94. The 4 mechanisms that we do not support can be considered out of our scope, e.g., \'93Use opens source solutions\'94 or \'93Use suitable protocols\'94. }